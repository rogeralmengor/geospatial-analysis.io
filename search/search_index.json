{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"About me <p>Hello, I am Roger Almengor Gonz\u00e1lez, an environmental science professional specializing in remote sensing and geographic information sciences. My technical skills include database management, design, and execution, as well as programming in Python, Julia, and C. I have experience managing forestry projects, including mixed-species reforestation in my home country.</p> <p> In my free time, I enjoy learning about geopolitics, playing musical instruments, and hiking in the Alps on the Germany-Austria border, near my based town.</p> <p> For more detailed information about my professional experience, please download my updated CV from the following link, or visit it, at the CV section of this site.</p> <p>A satellite image of my hometown, David, Chiriqu\u00ed, a place that holds a special spot in my heart, and one that I dearly miss.</p> <p></p>"},{"location":"CV/","title":"CV","text":"Roger Almengor Gonz\u00e1lez Geospatial Developer  <p>Date and place of birth: 16/02/1987 David Chiriqu\u00ed, Republic of Panama</p> <p>Nationality: Panamanian</p> <p>Place of Residence: F\u00fcssen / Germany</p> <p>Civil status: single</p> <p>Education: </p> <p>Date:\u00a0 </p> <p>10/2014 \u2013 08/2017</p> <p>Institution</p> <p> <p>TU Munich</p> </p> <p>Principal subjects/occupational skills covered</p> <p>Landscape Management, Forest Management, GIS, Remote Sensing</p> <p>Degree(s) or Diploma(s) obtained:</p> <p>M. Sc. Sustainable Ressource Management</p> <p> </p> <p> </p> <p>Date:\u00a0 </p> <p>03/2005 \u2013 08/2010</p> <p>Institution</p> <p> <p>University of Panama</p> </p> <p>Principal subjects/occupational skills covered</p> <p>Environmental Management</p> <p>Degree(s) or Diploma(s) obtained:</p> <p>Engineer</p> <p> </p> <p>Language skills: </p> <p>Mother tongue(s): Spanish</p> <p> </p> <p>Understanding</p> <p>Speaking</p> <p>Writing</p> <p> </p> <p>Listening</p> <p>Reading</p> <p>Spoken interaction</p> <p>Spoken production</p> <p> </p> <p>English</p> <p>C1</p> <p>C1</p> <p>C1</p> <p>C1</p> <p>C1</p> <p>German</p> <p>C1</p> <p>C1</p> <p>C1</p> <p>C1</p> <p>C1</p> <p>https://en.wikipedia.org/wiki/Common_European_Framework_of_Reference_for_Languages</p> <p> </p> <p> </p> <p>Digital competence:</p> <p>Information processing</p> <p>Communication</p> <p>Content  creation</p> <p>Safety</p> <p>Problem  solving</p> <p>Proficient user</p> <p>Proficient user</p> <p>Proficient user</p> <p>Proficient user</p> <p>Proficient user</p> <p>Levels: Basic user - Independent user - Proficient user</p> <p>Digital competences - Self-assessment grid</p> <p>Computer skills:</p> <ul> <li>Proficient user of office suite (word processor, spread sheet, presentation software)</li> <li>Proficient user of GIS software (ArcPro, ArcGIS, QGIS, SAGA, eCognition)</li> <li>Proficient user of programming languages for geospatial analysis (Python, Julia, JavaScript)</li> </ul> <p> </p> <p>Other skills / Other Training: </p> <p> </p> <p>2012\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Introduction to Mirasilv (Forest Inventory); INFOA</p> <p>2016\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Python for Everyone</p> <p>2016\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Going to Places with Spatial Analysis in ArcPro; ESRI</p> <p>2016\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Earth Imagery at Work; ESRI</p> <p>2016\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Exploring GIS Maps; ESRI</p> <p>2018 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 German Language Certificate (DSZ-B); Kolping Academy</p> <p>2018\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Applied Radar Remote Sensing; Friedrich-Schiller-Universit\u00e4t Jena</p> <p>2019\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Applied Machine Learning in Python; Coursera</p> <p>2019\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Introduction to Data Science in Python; Coursera</p> <p>2020\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Image Processing with Python; Python Academy</p> <p>2023\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Github and Git; Coursera</p> <p>2023\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Cyber Security; Knowbe4</p> <p> </p> <p>Key qualifications:</p> <ul> <li>Programming: Python, Ansi C, SQL, UML, Julia, JavaScript (GEE), CSS, HTML, LaTeX, Markdown.</li> <li>Use of relational databases: PostgreSQL</li> <li>Use of geospatial databases: PostGIS</li> <li>GIS and Satellite imagery analysis: ArcGIS, QGIS, SAGA</li> <li>Operating Systems: Linux, Windows</li> </ul> <p> </p> <p>Countries of Work Experience:</p> <p>Republic of Panama</p> <p> </p> <p>Employment Record: </p> <p>Period</p> <p>Employing organization and your title/position. </p> <p>Contact information</p> <p>Country </p> <p>Summary of activities performed </p> <p>Seit 01/2022</p> <p> <p>GAF AG</p> </p> <p>info@gaf.de</p> <p>Germany</p> <p>GIS \u2013 Software Developer</p> <p>05/2022 \u2013 08/2022</p> <p> <p>Saasmetrix GmbH</p> </p> <p>hello@saasmetrix.io</p> <p>Germany</p> <p>Backend Developer</p> <p>01/2020 \u2013 12/2021</p> <p> <p>German Aerospace Centre</p> </p> <p>Info@gaf.de</p> <p>Germany</p> <p>Scientific Researcher</p> <p>04/2017 \u2013 12/2019</p> <p> <p>GAF AG</p> </p> <p>info@gaf.de</p> <p>Germany</p> <p>Geospatial Analyst</p> <p>02/2017 \u2013 03/2019</p> <p> <p>GAF AG</p> </p> <p>info@gaf.de</p> <p>Germany</p> <p>Intern (GIS \u2013 Remote Sensing)</p> <p>08/2016 \u2013 10/2016</p> <p> <p>Remote Sensing Solutions GmbH</p></p> <p>info@rssgmbh.de</p> <p>Germany</p> <p>Intern (GIS \u2013 Remote Sensing)</p> <p>09/2011 \u2013 09/2013</p> <p> <p>Forest Finance Panama</p></p> <p>info@forestfinance.com</p> <p>Panama</p> <p>Forest and Environment Engineer</p> <p> </p> <p>Professional experience record: </p> <p>Name of assignment or project:</p> <p>CAP \u2013 AMS</p> <p>Year:</p> <p>01/2021 \u2013 jetzt</p> <p>Location:</p> <p>Germany</p> <p>Client (contact details):</p> <p> </p> <p>Different federal authorities like the Federal Ministry of Agriculture in a multi-year contract</p> <p>Main project features: </p> <p>Implementation and further development of automatic remote sensing-based monitoring within the framework of the Common Agricultural Policy (CAP).</p> <p>Positions held:</p> <p>Geospatial Developer</p> <p>Activities performed:</p> <p>Development of tools for raster, vector, and machine learning, as well as interaction with a PostGIS database.</p> <p>Creation of tools for automating agricultural parcel monitoring using dense temporal image series from Sentinel-1, Sentinel-2, and Planet Fusion to detect deviations during the growth period.</p> <p> </p> <p> </p> <p>Name of assignment or project:</p> <p>HICAM</p> <p>Year:</p> <p>01/2020 \u2013 12/2021</p> <p>Location:</p> <p>Germany</p> <p>Client (contact details):</p> <p>Helmholz for Environmental Research</p> <p>Main project features: </p> <p>As part of the HI-CAM project, the DLR, in collaboration with the Helmholtz Centre for Environmental Research, analyses the impact of climate change on cropland, grassland, and aquatic ecosystems. One of the objectives is to create a classification workflow for the year 2018 using in-situ data and Sentinel-1/2 time series, thus support further investigation for the adaptation of agricultural practices to climate change.</p> <p>Positions held:</p> <p>Scientific Researcher</p> <p>Activities performed:</p> <p>Creation and conceptualization of a map view of crop types for the years 2019-2020 at national level in Germany using the programming languages C and Python.</p> <p>Collaboration for the publication of a scientific report in a remote sensing and GIS journal related to the classification of crop types using images from the Sentinel-1 and Sentinel-2 missions.</p> <p> </p> <p> </p> <p>Name of assignment or project:</p> <p>High Resolution Layers (Grassland and Forest)</p> <p>Year:</p> <p>2018</p> <p>Location:</p> <p>Germany</p> <p>Client (contact details):</p> <p>European Commission</p> <p>Main project features: </p> <p>Creation of High-Resolution Raster Layers at European level with a 20-100 m spatial resolution with thematic classes.</p> <p>Positions held:</p> <p>Geospatial Analyst</p> <p>Activities performed:</p> <p>Processing of raster and vector layers for the classification of pasture and forest areas at the European level. Creation of rasterized products for each member state of the European Union in different geographic projections.</p> <p>Development of workflows for quality assurance of geospatial products.</p> <p> </p> <p> </p> <p>Name of assignment or project:</p> <p>Pure Forest</p> <p>Year:</p> <p>09/2011 \u2013 09/2013</p> <p>Location:</p> <p>Republic of Panama</p> <p>Client (contact details):</p> <p>Federal Agency for Nature Conservation</p> <p>Federal Ministry for the Environment, Nature Conservation, Building and Nuclear Safety</p> <p>Pure Forest GmbH</p> <p>Main project features: </p> <p>The project focuses on the certified management of forest areas and the reforestation of mixed forests in previously harvested areas. It involves the replacement of an existing teak monoculture with Acacia mangium as a preparatory step toward the transformation into native mixed forest.</p> <p>Positions held:</p> <p>Forest and Environmental Engineer</p> <p>Activities performed:</p> <p>Forestry and Environmental Inventory in Agricultural Areas. Surveying and Parcelling of Areas Based on Growth Projections.</p> <p>Coordination of Timber Harvesting, Transportation, and Intermediate Sales.</p> <p> </p> <p>Publications:</p> <p>Asam S, Gessner U, Almengor Gonz\u00e1lez R, Wenzl M, Kriese J, Kuenzer C. Mapping Crop Types of Germany by Combining Temporal Statistical Metrics of Sentinel-1 and Sentinel-2 Time Series with LPIS Data. Remote Sensing. 2022; 14(13):2981. https://doi.org/10.3390/rs14132981</p> <p>Driving licence: A</p> <p>Contact information : e-mail : rogeralmengor@gmail.com, phone : +49 (0)1626290775</p> <p> </p>."},{"location":"blog/","title":"About this blog","text":"This blog is composed of small geospatial analyses, which I have done, primarily tackling questions about environmental phenomena. Most of the examples are written in the JavaScript language for the Google Earth Engine interface. Examples in Python, and the Julia language will also be incorporated over time."},{"location":"blog/#blogs","title":"Blogs","text":"<p>{{ blog_content }}</p>"},{"location":"blog/posts/download_brandenburg_data/","title":"A database worth downloading for time series analysis","text":"<p>Obtaining ground-truth data for geospatial analysis can be a daunting task for geospatial developers or scientists in general. This is often due to the limited manpower, as well as the limited organization, and limited budget to carry out such large tasks as a spatial census of what is happening on the Earth\u2019s surface at a temporal resolution (the time taken between each survey) sufficient to perform time series analysis.</p> <p>Today I would like to make a parenthesis and leave aside all this discouraging panorama, to present you some geospatial data that seem to me an exception to the situation, and that could be of really interesting for further time series analyses in agriculture.</p> <p>This dataset are the LPIS Data (Land Parcel Identification System), for the federal state of Brandenburg (Germany), for years 2010 until 2022 (and the years to come). It is outstanding since it contains information of parcels dedicated to agriculture. Some of the information we can derived from it are the crop types, the parcel id (without any personal information of the parcel\u2019s owner), land use code (agriculture, grassland, etc.), and year of cultivation. Although not all parcels in this location are represented, we can assure that a great amount of agricultural parcels can be depicted in this dataset for every year.</p> <p>With that being said, we will go through to the steps to download the data, and after we will make it available in a Google Earth Engine account.</p>"},{"location":"blog/posts/download_brandenburg_data/#how-to-download-the-raw-data","title":"How to download the \u201craw\u201d data","text":"<p>When entering Invekos Brandenburg, we can pin point the result that will lead us to the webpage of the Geoportal with geospatial datasets for the state of Brandenburg. Click on the entry \u201cDaten aus dem Agrarf\u00f6rderantrag\u201d. This is the LPIS Data for Germany. The name Invekos stands for LPIS in Germany.</p> <p> 01. Google Search </p> <p>Once in this geoportal, the web page should look like this.</p> <p> 02. Geoportal Brandenburg </p> <p>Now scroll down and click on the geobrocker link as shown in the yellow highlighted text.</p> <p> 03. Link to geobrocker </p> <p>Once on the geobrocker page, click on the button \u201cWeiter zu Bestellvorgang\u201d.</p> <p> 04. Weiter zum Bestellvorgang </p> <p>On the following page, you can see a small interactive map of the federal state of Brandenburg in Germany. Below you will find the button \u201cDatenauftrag Erzeugen\u201d, click there.</p> <p> 05. Button Datenauftrag erzeugen </p> <p>Now you will see a page with some fields to which you can change the input parameters. For example the example below shows the parameters for downloading agricultural parcel data in Shape format, year 2022 and WGS 84 coordinate system. Then click on the \u201cWeiter\u201d (means \u201cnext\u201d in german), button.</p> <p> 06. Settings for downloading area </p> <p>Once you see the button \u201cWarenkorb\u201d, which is \u201ccart\u201d in german, you will be redirected to the status your requested data.</p> <p> 07. Cart </p> <p>The status of your shopping cart will be displayed, and you will then be able to check out by pressing the \u201czu Kasse gehen\u201d button.</p> <p> 08. Check out </p> <p>For me as you can see below, the problem is now that I did not do a log in before making the data request. So immediately when you click on the check out, you will be redirected to the log in page. If you have credentials (user name and password), just enter them. But in this example, we are going to make a request for our username and password. So, click on the \u201cRegistrieren\u201d button, so we can start the registering process.</p> <p> 09. Log in </p>"},{"location":"blog/posts/download_brandenburg_data/#registration-process","title":"Registration process","text":"<p>Below, you will find an example of the fields as I filled them out. Fill in the necessary fields to become a registered user for this web portal.</p> <p> 10. Registering </p> <p>Accept the terms of use and click on \u201cEingabe \u00fcberpr\u00fcfen\u201d.</p> <p> 11. Accepting the terms of use </p> <p>Check that the information provided is correct, and click on register, to begin the registration process.</p> <p> 12. Checking the user information </p> <p>If everthing goes well, the message \u201cIhre Registrierung verlief erfolgreich. Sie bekommen Ihr Passwort per Mail zugesendet.\u201d, which means your registration has been successful, you will receive a password by email.</p> <p> 13. Registration confirmation </p>"},{"location":"blog/posts/download_brandenburg_data/#log-in","title":"Log in","text":"<p>Now click on \u201cweiter zur Anmeldung\u201d.</p> <p> 14. Next steps to log in </p> <p>After a few minutes, you will receive an email with your username and password.</p> <p> 15. User information received per E-Mail </p> <p>Enter your password and username to enter the geoportal as a registered user. I had to insist sometimes, trying both: copying the information in my clipboard form my E-Mail, or entering my username and password through my keyboard. I persisted until it worked, the same may happen to you. Don\u2019t get discouraged, and keep at it until it works. There might be a delayed until your confirmation is down in your E-Mail, and when you actually can use it to log in.</p> <p> 16. Log in </p>"},{"location":"blog/posts/download_brandenburg_data/#download-data","title":"Download data","text":"<p>You can go back to your cart overview, and see the data that is ready to be requested. Click on \u201cKaufen\u201d again.</p> <p> 17. Click on \"Kaufen\" (Buy) again now, as a registered user </p> <p>Now your job is to wait until you find a message in your E-Mail box, about the confirmation that your data is downloadable. First you will received a message about the request, and after a message when your data is ready to be downloaded.</p> <p> 18. Requested data conirmation </p> <p> 19. Download data confirmation </p> <p>And that\u2019s basically it. By clicking on the download link found in the confirmation message in your E-Mail box, you will be redirected to a page like the one below. By clicking on the highlighted button below, the download process will start.</p> <p> 20. Download link available </p>"},{"location":"blog/posts/download_brandenburg_data/#creating-an-asset-in-google-earth-engine","title":"Creating an asset in Google Earth Engine","text":"<p>Now that we have downloaded our data in Shape format, let\u2019s go to our Google Earth Engine account and import the dataset for the year 2022 and add a description of the dataset that will help us to highlight its main features. irst of all let\u2019s open the google earth engine home page, and click on the tab code editor to open our google earth engine staff in case we have already created one. For more information about how to open an account for google earth engine visit the following link: https://developers.google.com/earth-engine/guides/access</p> <p> 21. Opening Google Earth Engine Code Editor </p> <p>On the left hand side of the code editor we can see several tabs among which is the Assets tab. Let\u2019s click on this one.</p> <p> 22. Code editor Interface </p> <p>When we open it we can see some of the assets we have already uploaded, if we have done so in the past. However, for the sake of this tutorial, we are going to assume that you are new to uploading assets in google earth engine.</p> <p> 23. Asset's tab </p> <p>Now please click on the new tab to start the process of creating a new asset.</p> <p> 24. Creating new asset </p> <p>You will see that you have several formats supported by google earth engine to be uploaded among which are CSV files, images, image collections, folders and shapefiles. This last one is the one we are interested in since the formats we downloaded in the previous section come in this type of format.</p> <p> 25. Uploading Shapefile </p> <p>Under the header source files, you will see a button with the label select, click on it to browse the files that are part of the shapefile and that you will need to upload to create this asset.</p> <p> 26. Selecting Shapefile from local folder </p> <p>As you can see I have selected the .shp, .shx, .dbf, and .prj extensions which are the minimum necessary to upload as far as the shapefile is concerned (I did not upload the .cpg file at the time of writing this blog post, as in the past this type of extension was not allowed, it seems it is now. I may have made a mistake and this type of extension was always allowed, but as far as I remember it was the restriction I was aware of with this extension).</p> <p> 27. Selecting supported files to create asset </p> <p>Now press the upload button, to start the process of uploading the file to your account, as a google earth engine asset.</p> <p> 28. Pressing upload to trigger the task </p> <p>You will see the \u201cTask\u201d tab in yellow, which means that the upload process is in progress.</p> <p> 29. Task started </p> <p>By clicking on this tab you will see the progress of the upload process of this file.</p> <p> 30. Upload progress </p> <p>At the end of the upload process, you will see the file listed in your assets.</p> <p> 31. Assets uploaded </p> <p>Now let\u2019s click on this dataset to see what google earth engine has already put at our disposal to describe this asset. We can observe three tabs: description, features and properties. In description we can see that no text describing the dataset has been given.</p> <p> 32. Description tab </p> <p>In features, we can see that google earth engine already provides us with the name of the different columns in the attribute table of this asset, as well as the type of data that each column holds.</p> <p> 34. Features tab </p> <p>When clicking on the properties tab, we can see that is also empty.</p> <p> 33. Properties tab </p> <p>Now I wanted to add information related to this dataset, taking advantage of the Description tab. In this one we can format the text using the markdown syntax, since it is supported by this feature of the asset\u2019s manager of google earth engine. To do this just change the \u201cEdit\u201d option at the top right and start adding the text that best describes the asset you just uploaded. Also at the bottom left you can find the option to add the time period this dataset covers.</p> <p> 34. Adding asset's description </p> <p>When you again disable the edit option, you will be able to see how the description will be rendered for users to view.</p> <p> 35. Product\u2019s description in viewers mode </p> <p>And that\u2019s all, you need to upload an asset to your google earth engine account. In this post, you have learned how to download LPIS data for the state of brandenburg, and how to upload it from your locally saved shape format on your computer to your google earth engine account as an asset, as well as add a description that can be rendered in a more apealign way using markdown syntax.</p>"},{"location":"blog/posts/functional_programming/","title":"Stop Wasting Time on Intermediate Variables: function composition to the rescue!","text":"<p>Have you ever found yourself trying to make many array manipulations, and storing the results in temporal variables such as temp1, temp2, temp_prefinal, temp_before_final, etc.?</p> <p>I had this sort of problem, until I came across to a technique called function composition. This can be applied in python using the functools, and it\u2019s undoubtedly a good tool for any data scientist to write efficient and readable code. That will avoid the need to store intermediate variables (with poor names ;o) ) and make your code easier to read and understand.</p> <p>Consider the following code that calculates the sum of the squares of the first five integers using intermediate variables:</p> <p>```python title=\"example_1.py\" linenums=\"1\"</p>"},{"location":"blog/posts/functional_programming/#bad-practice-using-intermediate-variables","title":"Bad practice: using intermediate variables","text":"<p>import numpy as np</p> <p>arr = np.array([1, 2, 3, 4, 5]) squared_arr = np.square(arr) sum_of_squares = np.sum(squared_arr) print(sum_of_squares)  # Output: 55</p> <pre><code>\nWhile this approach can be useful for some situations, it can become cumbersome when working with larger datasets and complex manipulations.\n\nBy chaining NumPy array manipulations, you can save time and avoid creating multiple intermediate variables. That\u2019s when the technique of function composition comes in handy.\n\nYou can use the functools.reduce method to apply a list of functions to an initial input value, allowing you to further streamline your code.\n\n```python title=\"example_2.py\" linenums=\"1\"\n# Using functools.reduce to apply a list of \n# functions to an initial input value\nimport numpy as np\nimport functools\n\narr = np.array([1, 2, 3, 4, 5])\nsum_of_squares = functools.reduce(lambda x, f: f(x), \n                              [np.square, np.sum], arr)\n\nprint(sum_of_squares)  # Output: 55\n</code></pre> <p>In this example, functools.reduce applies the list of functions [np.square, np.sum] to the initial input value arr in a sequential manner, with each function taking the output of the previous function as its input. The lambda function lambda x, f:f(x) is used to apply each function in the list to the previous result.</p> <p>Using functools.reduce can be a powerful way to streamline your code and avoid the need for intermediate variables when working with NumPy arrays.</p> <p>Regarding functional programming, functools.reduce is a common technique used in functional programming languages like Haskell and Lisp, where functions are first-class citizens and can be treated like any other value. While some developers see functional programming as the best way to write software, others prefer object-oriented or procedural programming paradigms.</p> <p>As a data scientist, I believe it\u2019s important to choose the best approach for the task at hand. While you may not be a fan of functional programming as a paradigm, you can still incorporate functional programming techniques like functools.reduce when they make sense for your input data, data flow, and outputs. By taking a pragmatic approach and combining different programming paradigms, you can write efficient and readable code that meets your project goals.</p> <p>Now that you\u2019ve seen how to use NumPy\u2019s dot function chaining and functools.reduce to streamline your code, why not try it out in some of your code? Whether you\u2019re working on a data analysis project or a machine learning model, these techniques can help you write more efficient and readable code. So go ahead and give it a try!</p> <p></p>"},{"location":"blog/posts/interactive_staging/","title":"Using git add -N and git add -patch to split a single's file commit into several commits","text":"<p>\"We've all been there.\" You're making changes to one or more files, with a clear goal: implement a logging system. But as you tweak lines of code, you also end up improving a function here, removing some comments, adding a new function, getting rid of a few print statements\u2026 all unrelated to the logging system. Now, you're stuck with a bunch of mixed changes, and it's time to git add. Imagine you've already committed everything under the message \"changes to the logging system\"\u2014sound familiar? Frustrating, right?</p> <p>Fortunately, Git provides a great tool called interactive staging. While it\u2019s typically used for organizing changes from the working directory to the staging area, you can also apply it to older commits. This lets you cleanly organize your commits by theme, so each commit truly reflects the purpose of the changes.</p> <p>In this tutorial, we'll explore how to do that and answer this key question:</p> <p>!!! question     How to split a commit that adds several independent lines of code, in a commit down the tree?</p>"},{"location":"blog/posts/interactive_staging/#create-initial-python-file","title":"Create initial python file.","text":"<p>The first thing we do is to create a file called math_operations.py. I am in a linux environment using coding spaces, so I create the file using the touch command.</p> <p>!!! warning \"Creating initial file\"     <code>bash     $ touch math_operations.py</code></p>"},{"location":"blog/posts/interactive_staging/#create-basic-arithmethic-functions-and-commit","title":"Create basic arithmethic functions and commit","text":"<p>Now we want to create the 4 functions for basic arithmetic operations (add, subtract, multiply and divide) in the math_opeartions.py file.</p> <p>!!! abstract \"math_operations.py\"     ```python     def add(a: float, b: float) -&gt; float:         \"\"\"Add two numbers.\"\"\"         return a + b</p> <pre><code>def subtract(a: float, b: float) -&gt; float:\n    \"\"\"Subtract b from a.\"\"\"\n    return a - b\n\ndef divide(a: float, b: float) -&gt; float:\n    \"\"\"Divide a by b.\"\"\"\n    return a / b\n\ndef multiply(a: float, b: float) -&gt; float:\n    \"\"\"Multiply a and b.\"\"\"\n    return a * b\n```\n</code></pre> <p>We commit the changes:</p> <p>!!! warning \"Adding and commiting changes in initial file\"     <code>bash     $ git add math_operations.py     $ git commit -m \"feat: add module basic arithmetic operations.\"</code></p>"},{"location":"blog/posts/interactive_staging/#creating-factorial-function","title":"Creating factorial function","text":"<p>To create a bit of complexity in our rebasing, we add the factorial function to the math_operations.py file.</p> <p>!!! abstract \"math_operations.py\"     ```python     def add(a: float, b: float) -&gt; float:         \"\"\"Add two numbers.\"\"\"         return a + b</p> <pre><code>def subtract(a: float, b: float) -&gt; float:\n    \"\"\"Subtract b from a.\"\"\"\n    return a - b\n\ndef divide(a: float, b: float) -&gt; float:\n    \"\"\"Divide a by b.\"\"\"\n    return a / b\n\ndef multiply(a: float, b: float) -&gt; float:\n    \"\"\"Multiply a and b.\"\"\"\n    return a * b\n\ndef factorial(n: int) -&gt; int:\n    \"\"\"Calculate the factorial of n.\"\"\"\n    if n == 0 or n == 1:\n        return 1\n    else:\n        return n * factorial(n-1)\n```\n</code></pre> <p>We add and commit the changes:</p> <p>!!! warning \"Adding and commiting new changes\"     <code>bash     $ git add math_operations.py     $ git commit -m 'feat: add factorial function.</code></p> <p>We visualize our commit's tree by running:</p> <p>!!! warning \"git log --oneline --graph main\"     <code>bash     * c291adb (HEAD -&gt; main) feat: add factorial function.     * fd18571 feat: add module basic arithmetic operations.</code></p>"},{"location":"blog/posts/interactive_staging/#starting-the-interactive-rebasingstaging","title":"Starting the interactive rebasing/staging.","text":"<p>Now we'll use the interactive rebasing to start our split of the first commit we did in this tutorial (This commit is the second commit going from top-down in our commit's tree):</p> <p>!!! warning \"Starting interactive rebasing to second commit down the tree\"     <code>bash      $ git rebase -i HEAD~2     hint: Waiting for your editor to close the file...</code></p> <p>A text editor, (normaly VIM will open... if you set another text editor then, the latter will open), opens, and asks you to change the actions of the commit list, from which you are doing the rebasing. We change the pick keyword for the edit keyword.</p> <p>!!! warning \"Editing the git todo file\"     ```bash     edit fd18571 feat: adding module basic arithmetic operations.     pick c291adb feat: add factorial function.</p> <pre><code># Rebase 8cca62b..36710a0 onto 8cca62b (2 commands)\n#\n# Commands:\n# p, pick &lt;commit&gt; = use commit\n# r, reword &lt;commit&gt; = use commit, but edit the commit message\n# e, edit &lt;commit&gt; = use commit, but stop for amending\n# s, squash &lt;commit&gt; = use commit, but meld into previous commit\n# f, fixup [-C | -c] &lt;commit&gt; = like \"squash\" but keep only the previous\n#                    commit's log message, unless -C is used, in which case\n#                    keep only this commit's message; -c is same as -C but\n#                    opens the editor\n# x, exec &lt;command&gt; = run command (the rest of the line) using shell\n# b, break = stop here (continue rebase later with 'git rebase --continue')\n# d, drop &lt;commit&gt; = remove commit\n# l, label &lt;label&gt; = label current HEAD with a name\n# t, reset &lt;label&gt; = reset HEAD to a label\n# m, merge [-C &lt;commit&gt; | -c &lt;commit&gt;] &lt;label&gt; [# &lt;oneline&gt;]\n#         create a merge commit using the original merge commit's\n#         message (or the oneline, if no original merge commit was\n#         specified); use -c &lt;commit&gt; to reword the commit message\n# u, update-ref &lt;ref&gt; = track a placeholder for the &lt;ref&gt; to be updated\n#                       to this position in the new commits. The &lt;ref&gt; is\n#                       updated at the end of the rebase\n#\n# These lines can be re-ordered; they are executed from top to bottom.\n#\n# If you remove a line here THAT COMMIT WILL BE LOST.\n#\n# However, if you remove everything, the rebase will be aborted.\n#\n```\n</code></pre> <p>If you are in vim, you can close the file by pressing <code>:wq</code>. Once closed you can make a reset of the HEAD, because we are at the level of the commit we want to split.</p> <p>!!! warning \"Resetting the last changes\"     <code>bash     $ git reset HEAD^     Unstaged changes after reset:     M       docs/blog/math_operations.py</code></p> <p>As you can see the the math_opeartions.py file has gone to a unstaged status. And we can start doing our modifications of the commits.</p> <p>This is an important concept to bear in mind when doing this specific modification of the git history. There is the staging area in a git repository, which contains a copy of the files being changed in the next commits. However since the math_operations.py file does not exists in the previous commit, in order to add changes in this file, we have to create a file which will be patched against. The following command will do that for us, which basically adds an empty <code>math_operations.py</code> file in the index to start the interactive staging.</p> <p>!!! warning \"Adding file to index\"     <code>bash     $ git add -N math_operations.py</code></p> <p>Once we do that, we can start adding the patches.</p> <p>!!! warning \"Start adding patches\"     <code>bash     $ git add -p match_operations.py     diff --git a/math_operations.py b/math_operations.py     new file mode 100644     index 0000000..615a19b     --- /dev/null     +++ b/math_operations.py     @@ -0,0 +1,15 @@     +def add(a: float, b: float) -&gt; float:     +    \"\"\"Add two numbers.\"\"\"     +    return a + b     +     +def subtract(a: float, b: float) -&gt; float:     +    \"\"\"Subtract b from a.\"\"\"     +    return a - b     +     +def divide(a: float, b: float) -&gt; float:     +    \"\"\"Divide a by b.\"\"\"     +    return a / b     +     +def multiply(a: float, b: float) -&gt; float:     +    \"\"\"Multiply a and b.\"\"\"     +    return a * b     \\ No newline at end of file     (1/1) Stage addition [y,n,q,a,d,e,p,?]?</code></p> <p>As you can see, since all the changes were introduced in the same commit at once, the patches, which are called hunks in this tool, appear as the entire file. That is not very usefull, since we want to create single commits for every function we are introducing. For that, lets type the option e, which stands for editing. And we'll start adding the changes one by one, in single commits.</p> <p>When typing <code>e</code>, a file named addp-hunk-edit.diff will be opened in your text editor, with the following contents:</p> <p>!!! warning \"Manual editing of hunks\"     <code>bash     # Manual hunk edit mode -- see bottom for a quick guide.     @@ -0,0 +1,15 @@     +def add(a: float, b: float) -&gt; float:     +    \"\"\"Add two numbers.\"\"\"     +    return a + b     +     +def subtract(a: float, b: float) -&gt; float:     +    \"\"\"Subtract b from a.\"\"\"     +    return a - b     +     +def divide(a: float, b: float) -&gt; float:     +    \"\"\"Divide a by b.\"\"\"     +    return a / b     +     +def multiply(a: float, b: float) -&gt; float:     +    \"\"\"Multiply a and b.\"\"\"     +    return a * b     \\ No newline at end of file     # ---     # To remove '-' lines, make them ' ' lines (context).     # To remove '+' lines, delete them.     # Lines starting with # will be removed.     # If the patch applies cleanly, the edited hunk will immediately be marked for staging.     # If it does not apply cleanly, you will be given an opportunity to     # edit again.  If all lines of the hunk are removed, then the edit is     # aborted and the hunk is left unchanged.</code></p> <p>As you can see all the lines with the four functions we want to add individually are listed as an entire patch.</p> <p>!!! danger \"Important!\"     If you're using Git with VSCode and the editor doesn't open when you press 'e' during interactive staging (git add -p), there are a few steps you can take to resolve this issue:</p> <pre><code>Check your Git configuration:\n    Make sure Git is configured to use VSCode as your default editor. \n    You can do this by running:\n        ```git config --global core.editor \"code --wait\"```\n    This sets VSCode as the default editor and tells Git to wait for the file to be closed before proceeding.\n</code></pre> <p>Let's just manually delete the functions subtract, divide and multiply, and save and close the changes. It should look like that: </p> <p>!!! warning \"Leaving only the lines we are going to first commit\"     <code>bash     # Manual hunk edit mode -- see bottom for a quick guide.     @@ -0,0 +1,15 @@     +def add(a: float, b: float) -&gt; float:     +    \"\"\"Add two numbers.\"\"\"     +    return a + b     +     \\ No newline at end of file     # ---     # To remove '-' lines, make them ' ' lines (context).     # To remove '+' lines, delete them.     # Lines starting with # will be removed.     # If the patch applies cleanly, the edited hunk will immediately be marked for staging.     # If it does not apply cleanly, you will be given an opportunity to     # edit again.  If all lines of the hunk are removed, then the edit is     # aborted and the hunk is left unchanged.</code></p> <p>After that being done, we can check out the status and the following should appear:</p> <p>!!! warning \"Checking out status\"     ```bash     $ git status     interactive rebase in progress; onto 6d5b423     Last command done (1 command done):     edit fd18571 feat: add module basic arithmetic operations.     Next command to do (1 remaining command):     pick 03413b7 feat: add factorial function.     (use \"git rebase --edit-todo\" to view and edit)     You are currently splitting a commit while rebasing branch 'main' on '6d5b423'.     (Once your working directory is clean, run \"git rebase --continue\")</p> <pre><code>Changes to be committed:\n(use \"git restore --staged &lt;file&gt;...\" to unstage)\n        new file:   math_operations.py\n\nChanges not staged for commit:\n(use \"git add &lt;file&gt;...\" to update what will be committed)\n(use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n        modified:   math_operations.py\n```\n</code></pre> <p>As you can see there are in the same file, changes that are ready to be commited (the step where we only left the function add, and remove all others), and changes to be staged (all the changes from the original hunk, or patch).</p> <p>Now just create a commit for the first function.</p> <p>!!! warning \"Commiting first changes\"     <code>bash     $ git commit -m feat: add add function.     [detached HEAD f78a69a] feat: add add function.     1 file changed, 3 insertions(+)     create mode 100644 math_operations.py</code></p> <p>Now we can again start the addition of the next patches.</p> <p>!!! warning \"Adding second patches (subtract function)\"     <code>bash     $ git add -p math_operations.py     diff --git a/math_operations.py b/math_operations.py     index 81d2d3b..615a19b 100644     --- a/math_operations.py     +++ b/math_operations.py     @@ -1,3 +1,15 @@     def add(a: float, b: float) -&gt; float:         \"\"\"Add two numbers.\"\"\"         return a + b     +     +def subtract(a: float, b: float) -&gt; float:     +    \"\"\"Subtract b from a.\"\"\"     +    return a - b     +     +def divide(a: float, b: float) -&gt; float:     +    \"\"\"Divide a by b.\"\"\"     +    return a / b     +     +def multiply(a: float, b: float) -&gt; float:     +    \"\"\"Multiply a and b.\"\"\"     +    return a * b     \\ No newline at end of file     (1/1) Stage this hunk [y,n,q,a,d,e,p,?]?</code></p> <p>As we can see now, the only patches to be added, are the lines where the subtract, divide and multiply function were added. We have to repeat the process, by deleting the lines we don't need by the next commit which is the addition of the subtract function. We have to start again the edit mode, by typing e, and then leaving only the lines which add the subtract function:</p> <p>!!! warning \"Manual editing of patches\"     <code>bash     $ e     # Manual hunk edit mode -- see bottom for a quick guide.     @@ -1,3 +1,15 @@     def add(a: float, b: float) -&gt; float:         \"\"\"Add two numbers.\"\"\"         return a + b     +     +def subtract(a: float, b: float) -&gt; float:     +    \"\"\"Subtract b from a.\"\"\"     +    return a - b     +     \\ No newline at end of file     # ---     # To remove '-' lines, make them ' ' lines (context).     # To remove '+' lines, delete them.     # Lines starting with # will be removed.     # If the patch applies cleanly, the edited hunk will immediately be marked for staging.     # If it does not apply cleanly, you will be given an opportunity to     # edit again.  If all lines of the hunk are removed, then the edit is     # aborted and the hunk is left unchanged.</code></p> <p>Now we add and commit the subtract function.</p> <p>!!! warning \"Commiting second patch\"     <code>bash     $ git commit -m \"feat: add subtract func.</code></p> <p>We have to repeat the same sequence for the functions remaining: divide and multiply. For sake of simplicity we won't add these steps in this tutorial, you surely at this point know how to do so for the remaning code. The message is clear: just type <code>git add -p &lt;file_name&gt;</code>, type <code>e</code> for the manual editing, delete the lines which don't belong to this commit, then <code>git commit -m &lt;message&gt;</code>, and repeat until the last commit.</p> <p>Now we can continue with the interactive rebasing, since the next commit is only to add the factorial function, and it should apply without complains.</p> <p>!!! success \"$ git rebase --continue\"     <code>bash     Successfully rebased and updated refs/heads/main</code></p> <p>Let's see our commit's tree:</p> <p>!!! success \"$ git log --oneline\"     <code>bash     c291adb (HEAD -&gt; main) feat: add factorial function.     92e7ccb feat: add multiply func.     2c08167 feat: add divide func.     2d5b8d7 feat: add subtract func.     2a3a6c2 feat: add add func.</code></p> <p>Yes!, we just created four commits which comprise the individual changes made in a file, from one commit which had all of the changes as a big chunk. In that way, we can keep our commit history cristal clear, and with individual, incremental changes on the file. If later we want to squeeze those changes or add them as an individual one by using the fix keyword, is our decision.</p>"},{"location":"blog/posts/interactive_staging/#references","title":"References","text":"<p>Chacon, Scott, and Ben Straub. Pro Git. 2nd ed. Berkeley, CA: Apress, 2014. Git Book</p>"},{"location":"blog/posts/julia_vs_python/","title":"Performance benchmarking for Julia and Python in a geospatial task.","text":"<p>A little while ago, I was confronted with a question. If you could start again to learn programming for geospatial analysis, where would you start?</p> <p>Knowing that the big geospatial data domains are raster data on the one hand, and vectors on the other, I would start with raster data first.</p> <p>Maybe this decision responds to something totally subjective, but I find that raster data allow us to review some topics such as time series analysis, raster algebra, geotransform, geographic vs projected coordinate systems, etc. If you find this statement out of place, or have a preference for vector data over raster data for getting started in the world of geospatial data programming, feel free to weigh in with your opinion to the contrary in the comment box.</p> <p>With that cleared up. I guess if you ask me what task would be good to start with, I would say a small script to calculate the normalized vegetation index (NDVI). Here we can review the concepts of raster algebra, creating a raster output to contain the results of the calculation and writing the raster to our file system.</p> <p>This post is more a comparison of two programming languages to perform the same task. One is Python, the language with which I started in this programming world, and the other is Julia, which I am currently exploring in order to see the advantages over interpreted languages like Python.</p> <p>The promises of Julia have been trumpeting across many programming blogs. A language that combines the syntax of a high level language, with the speed of a low level language, is what we have been promised.</p> <p>So I wanted to do this benchmarking between these two languages for the following task: calculate two arrays of integer values. The dimension of the array will be incremented in a \"FOR\" loop of a list of numbers that define the dimension in the x-direction and the y-direction of the array. Then these two matrices that simulate the values of a red and a near infrared band, will be used to calculate a normalized difference index (simulating the NDVI index), to finally write the results in an output raster. We didn't add any spatial reference to the raster datasets, for this is not the main focus of this post.</p> <p>The codes are posted here below.</p> Python Code ```python linenums=\"1\" #****************************************************************************** #                     Python Code  #                     NDVI Calculation #******************************************************************************  from osgeo import gdal import numpy import os import time  import numpy as np   array_sizes = [2500, 5000, 10000, 11000, 12000, 13000, 15000,               16000, 17000, 18000, 19000, 20000]  def main():     for i in array_sizes:          start_time = time.time()          b3 = np.random.randint(200, 900, size=(i, i))         b4 = np.random.randint(800, 5000, size=(i, i))          ndvi = (b4 - b3)/(b4 + b3)          drv = gdal.GetDriverByName ( \"GTiff\" )         output_filename = str(i) +  \"_python_NDVI.tif\"         dst_ds = drv.Create (output_filename, i, i, 1,                 gdal.GDT_Float64)         dst_ds.GetRasterBand(1).WriteArray ( ndvi.astype (np.float32) )         dst_ds = None          proc_time = time.time() - start_time          print(f\"Processing time {i}x{i}:::\" + str(proc_time))  if __name__ == \"__main__\":     main()  <pre><code>&lt;/details&gt;\n\n&lt;details&gt;\n&lt;summary&gt;Julia Code&lt;/summary&gt;\n```julia linenums=\"1\"\n#******************************************************************************\n#                   Julia Code\n#                   NDVI Calculation\n#******************************************************************************\n\nusing ArchGDAL\nusing  Glob\nusing TickTock\n\n\nprint(\"Current directory: \", pwd()) \n\n\narray_sizes = [2500, 5000, 10000, 11000, 12000, 13000, 15000,\n              16000, 17000, 18000, 19000, 20000]\n\n#define a function for the raster algebra\nfunction ndviCal(red,nir)\n    #ndviArray = (nir - red)/(nir + red)\n    ndviArray = Float64.((nir .- red)./(red .+ nir))[:,:,1]\n    return(ndviArray)\nend\n\n#foreach(array_sizes) do f\nfor i in array_sizes\n    tick()\n    redArrayFloat = Float64.(rand(200: 900, i, i))\n    nirArrayFloat = Float64.(rand(800: 5000, (i, i)))\n    ndviArray = ndviCal(redArrayFloat,nirArrayFloat)\n    print(i)\n    print(\"x\")\n    print(i)\n    #print(ndviBand)\n    string_array_size = string(i)\n    output_name = string_array_size * \"_julia_NDVI.tif\" \n    ArchGDAL.create(\n    output_name,\n    driver = ArchGDAL.getdriver(\"GTiff\"),\n    width=i,\n    height=i,\n    nbands=1,\n    dtype=Float64\n    ) do output_dataset\n    ArchGDAL.write!(output_dataset, ndviArray, 1)\n    tock()\n    end\nend\n</code></pre> <p>Below we collect the data in a table about the performance in seconds of each of the scripts for a variable input data size.</p> <p> </p> <p>We can observe that as the number of elements to process increases, the difference between the processing time between Julia and Python also increases. We can also observe that there is almost a difference of 5 seconds for a number of 400 million elements which would be a matrix of 20 000 x 20 000.</p> <p>Finally, we can see graphically in the following figure the plotting of the execution times of each program written in Python and Julia vs. the number of elements to be processed.</p> <p> </p> <p>Something interesting is to see that in the first review of the for loop Python recorded a faster execution time than Julia. The explanation for this is the variable type checking that takes place in the for loop. While Python has to know what type of variable it is in each of the cycles of the for loop, this process is done once and just once by Julia. </p> <p>In this post, we have been able to see the differences between Julia and Python for a simple geospatial task. Julia's runtime is faster for all but the first input size compared to Python. Some thoughts on why this may be were also given.</p>"},{"location":"blog/posts/lst_modis/","title":"Measuring land surface temperature with satellite imagery","text":""},{"location":"blog/posts/lst_modis/#introduction","title":"Introduction","text":"<p>In our previous post, we looked at the changes in the Cochea River watershed, and learned the capabilities of the Google Earth Engine to provide us with a visualization of these changes through satellite imagery. In this post, we are going to measure the changes in land temperature in this area in degrees Celsius, using the MODIS datasets, adding a line by line explanation of the code we are going to run to do this exercise.</p>"},{"location":"blog/posts/lst_modis/#step-by-step-code-explanation","title":"Step by step code explanation","text":"<p>The first thing that we need to do is to set our region of interest. We use the same Feature Collection from the shapefile of the province of Chiriqu\u00ed from our previous post. </p> <p>First we filter our Feature collection using the method ee.Filter.inList which find all the records in a feature collection which values for a certain column ('NAME_3' in this case), match a declared list ('districts'). We will work with the municipalities of Bijagual, Cochea and Las Lomas. </p> <p>Because there are one than two districs in different provices named 'Bijagual', we apply an additional filter to keep all records for which the province 'Chiriqu\u00ed' is found (filtering by the column 'NAME_1'). </p> <p>We add the layer, by applying an union algorithm, so the vector won't have any boundaries between the selected districts.</p> <p>```javascript linenums=\"1\" // Feature Collection  var districts = ee.List(['Bijagual','Cochea','Las Lomas']) var AOI = table.filter(ee.Filter.inList('NAME_3', districts)); var districts = AOI.filter(ee.Filter.eq('NAME_1', 'Chiriqu\u00ed')); Map.addLayer(districts.union())</p> <pre><code>\nNow we'll try to center our may view. First we filter our feature collection, and keep only the 'Bijagual' district. Now we get the x, and y coordinate from this district and store it in the centroid_cochea_coor variable, by using the series of methods geometry, centroid, coordinates and getInfo. By array subscript we get the x and y variable. Finally we center the Map view using the x, and y coordinates.\n\n```javascript linenums=\"1\" \n// Setting the Map to the coordinates of one of our districts\nvar cochea_district = table.filter(ee.Filter.eq('NAME_3', 'Bijagual'));\nvar centroid_cochea_coor = cochea_district.geometry().centroid().coordinates().getInfo();\nvar x = centroid_cochea_coor[0];\nvar y = centroid_cochea_coor[1];\nMap.setCenter(x, y, 10);\n</code></pre> <p>We set the visualization parameters to map values from 0 to a maximum of 40 for degrees Celsius, and pick up a color palette suitable to the range of values we want to represent.</p> <p>```javascript linenums=\"1\" // Raster Visualization Parameters var landSurfaceTemperatureVis = {   min: 0, max: 40,   palette: ['blue', 'limegreen', 'yellow', 'darkorange', 'red']};</p> <pre><code>\nFor this analysis we will divide a year into two seasons, the dry season and the rainy season. This is due to the seasonal pattern of the year that predominates in the tropics, which lacks the four seasons of the year that exist in other latitudes of the planet. The temporal analysis will be made for a period of 20 years, counting 2001 as year 1, until 2020.\n\nWe declare two variables (\"DrySeasonMedianCollection\" and \"WetSeasonMedianCollection\"), which will contain a collection of MODIS Land Surface images. There is no use (or it is not very recommended) of for loops to perform filtering and application of algorithms on a collection, so the body inside the \"ee.ImageCollection\" with which we create the two variables mentioned above seems a bit counterintuitive.\nGoogle Earth Engine uses an approach more inclined to functional programming than imperative or object-based programming, mapping functions to collections that can be vector data called \"Feature Collections\", or Images called \"ImageCollections\" (it can also be applied to another type of Collections, Lists, but these are the most interesting cases for geospatial data analyzers).\nWhat is done is to create a list with ee.List.sequence taking the first year \"2001\" and the last year 2020, and on that list we are going to apply the function \"createDrySeasonMedianComposite\", and \"createWetSeasonMedianComposite\" respectively.\n\n```javascript linenums=\"1\"\n// Image Collection MODIS Surface Temperature Median Values \n// (Dry Season January - March)\n// (Wet Season April - December)\nvar startYear = 2001;\nvar endYear = 2020;\nvar DrySeasonMedianCollection = ee.ImageCollection(\n  ee.List.sequence(startYear, endYear)\n    .map(createDrySeasonMedianComposite)\n);\n\nvar WetSeasonMedianCollection = ee.ImageCollection( \n  ee.List.sequence(startYear, endYear)\n  .map(createWetSeasonMedianComposite)\n);\n</code></pre> <p>The two functions below have a similar purpose, and the only thing that differentiates them is the time period used to filter the images. They use as argument \"year\", and based on that a startDate and endDate are created to delimit a period of time. Then a variable \"description\" is created, which is basically a data type \"string\" that comes from the concatenation of \"StartDate\" + \" TO \" + EndDate. The function returns an \"ImageCollection\", to which the \"filterBounds\" method is applied to obtain the images that intersect our region of interest (ROI). Then we apply to our \"ImageCollection\" the \"filterDate\" method, to obtain the images of the period we declared at the beginning, we select the layer \"LST_Day_1km\" and to that layer (raster layer) we multiply it by 0.02 which is the scale factor that comes in the MODIS products user guide for the transformation of digital numbers (DN) to Kelvin degrees, and finally we subtract the resulting values by 273.15 to transform the Kelvin degrees to Celcius which are the ones we will be working with. As you can see the same logic is observed in both functions, what changes are the time periods.</p> <p>```javascript linenums=\"1\" function createDrySeasonMedianComposite(year) { var startDate = ee.Date.fromYMD(year, 1, 1); var endDate = ee.Date.fromYMD(year, 3, 31); var description = startDate.format('yyyy-MM-dd') .cat(' TO ') .cat(endDate.format('yyyy-MM-dd')); return ee.ImageCollection('MODIS/061/MOD11A1') .filterBounds(districts) .filterDate(startDate, endDate) .select('LST_Day_1km') .map(function(img) { return img .multiply(0.02) .subtract(273.15) .copyProperties(img, ['system:time_start']); }) .median() .set('year', year) .set('description', description); }</p> <p>function createWetSeasonMedianComposite(year) { var startDate = ee.Date.fromYMD(year, 4, 1); var endDate = ee.Date.fromYMD(year, 12, 31); var description = startDate.format('yyyy-MM-dd') .cat(' TO ') .cat(endDate.format('yyyy-MM-dd')); return ee.ImageCollection('MODIS/061/MOD11A1') .filterBounds(districts) .filterDate(startDate, endDate) .select('LST_Day_1km') .map(function(img) { return img .multiply(0.02) .subtract(273.15) .copyProperties(img, ['system:time_start']); }) .median() .set('year', year) .set('description', description); }</p> <pre><code>\nTo the new imageCollection we apply the method \"toBands\" to convert it from its \"collection\" state to a \"multi-band\" image, using after the method \"select\" and a regular expression to get the images that come with a numerical prefix, starting by 0, e.g. (\"0_LST_Day_1km\", \"1_LST_Day_1km\" ...) .\n\n```javascript linenums=\"1\"\nDrySeasonMedianMultiBandImg = DrySeasonMedianCollection\n      .toBands()\n      .select('[0-9]{1,2}_LST_Day_1km');\n\nWetSeasonMedianMultiBandImg = WetSeasonMedianCollection\n      .toBands()\n      .select('[0-9]{1,2}_LST_Day_1km');\n</code></pre> <p>Now we create a dictionary called \"TempInfo\" which contains as key values the names of the layers in the multi-band images \"DrySeasonMedianMultiBandImg\" and \"WetSeasonMedianMultiBandImg\", and the value is a dictionary with ordinal values and the corresponding year for each band.</p> <p>```javascript linenums=\"1\" // Define a dictionary that associates band names with values  var TempInfo = {   '0_LST_Day_1km': {v: 1, f: '2001'},   '1_LST_Day_1km': {v: 2, f: '2002'},   '2_LST_Day_1km': {v: 3, f: '2003'},   '3_LST_Day_1km': {v: 4, f: '2004'},   '4_LST_Day_1km': {v: 5, f: '2005'},   '5_LST_Day_1km': {v: 6, f: '2006'},   '6_LST_Day_1km': {v: 7, f: '2007'},   '7_LST_Day_1km': {v: 8, f: '2008'},   '8_LST_Day_1km': {v: 9, f: '2009'},   '9_LST_Day_1km': {v: 10, f: '2010'},   '10_LST_Day_1km': {v: 11, f: '2011'},   '11_LST_Day_1km': {v: 12, f: '2012'},   '12_LST_Day_1km': {v: 13, f: '2013'},   '13_LST_Day_1km': {v: 14, f: '2014'},   '14_LST_Day_1km': {v: 15, f: '2015'},   '15_LST_Day_1km': {v: 16, f: '2016'},   '16_LST_Day_1km': {v: 17, f: '2017'},   '17_LST_Day_1km': {v: 18, f: '2018'},   '18_LST_Day_1km': {v: 19, f: '2019'},   '19_LST_Day_1km': {v: 20, f: '2020'}, }</p> <pre><code>\nNow we are going to declare two lists to obtain the values and the dictionary keys that will be used to define the axis values in the graphs.\n\n```javascript linenums=\"1\"\nvar xPropVals = [];\nvar xPropLabels = [];\n\nfor (var key in TempInfo){\n  xPropVals.push(TempInfo[key].v);\n  xPropLabels.push(TempInfo[key]);\n}\n</code></pre> <p>To unify the geometries of the different districts, we are going to join them using the \"union\" method in the \"FeatureCollection\".</p> <p>```javascript linenums=\"1\" // Apply the dissolve method to the Geometry object. print(districts) var geometryDissolve = districts.union();</p> <pre><code>\nNow we are going to define two graphs to print on our console. One will be created for the dry season, and the other for the rainy season. For this we use the ui.Chart.image object and apply the \"regions\" method. In this method we have to define the multiband image whose values we want to plot. Then the region in which we want to calculate the average temperature values, and a reducer, which in this case will be \"mean\" because we want to calculate the average of pixels in our study area for the given time period. For the seriesProperty parameter we set it to 'label', and define that the xLabels parameter will take the values from the xPropVals list.\nThe following are parameters for the elements found in the graph we are going to produce. First we define that it will be a line chart by setting the value of 'LineChart' using the 'setChartType' method.\nAmong the options we define the title, the name of the X axis (with the font type parameters), and the ticks for the horizontal axis will be the years, taken from the xPropLabels list.\nFor the vertical axis, we will give it the title Temperature (\u00b0C), define the parameters for the font. Finally we define the color that our line will take in the graph and the thickness of it.\nWe apply the print method to see our graph in the console.\n\n```javascript linenums=\"1\"\n// Define the chart and print it to the console.\nvar chartDrySeason = ui.Chart.image\n                .regions({\n                  image: DrySeasonMedianMultiBandImg,\n                  regions: districts.union(),\n                  reducer: ee.Reducer.mean(),\n                  scale: 500,\n                  seriesProperty: 'label',\n                  xLabels: xPropVals\n                })\n                .setChartType('LineChart')\n                .setOptions({\n                  title: 'Average (Median) Temperature (\u00b0C) Dry Season (Jan-Mar)',\n                  hAxis: {\n                    title: 'Year',\n                    titleTextStyle: {italic: false, bold: true},\n                    ticks: xPropLabels\n                  },\n                  vAxis: {\n                    title: 'Temperature (\u00b0C)',\n                    titleTextStyle: {italic: false, bold: true}\n                  },\n                  colors: ['f0af07', '0f8755', '76b349'],\n                  lineSize: 3\n});\nprint(chartDrySeason);\n\n// Define the chart and print it to the console.\nvar chartWetSeason = ui.Chart.image\n                .regions({\n                  image: WetSeasonMedianMultiBandImg ,\n                  regions: districts.union(),\n                  reducer: ee.Reducer.mean(),\n                  scale: 500,\n                  seriesProperty: 'label',\n                  xLabels: xPropVals\n                })\n                .setChartType('LineChart')\n                .setOptions({\n                  title: 'Average (Median) Temperature (\u00b0C) Rainy Season (Apr-Dec)',\n                  hAxis: {\n                    title: 'Year',\n                    titleTextStyle: {italic: false, bold: true},\n                    ticks: xPropLabels\n                  },\n                  vAxis: {\n                    title: 'Temperature (\u00b0C)',\n                    titleTextStyle: {italic: false, bold: true}\n                  },\n                  colors: ['0f8755', '76b349'],\n                  lineSize: 3\n});\nprint(chartWetSeason);\n</code></pre> <p> Average Median Temperature (\u00b0C) for the Dry Season (Jan-Mar) measured from the MODIS sensor in 20 years period </p> <p></p> <p> Average Median Temperature (\u00b0C) for the Wet Season (Apr-Dec) measured from the MODIS sensor in 20 years period </p> <p></p> <p>The following lines prepare an annotated collection (with a text showing the time period to which the layer belongs). This annotated collection will be displayed in the console as a GIF, which can be saved on your PC in GIF format.</p> <p>```javascript linenums=\"1\" // Define GIF visualization parameters. var gifParams = {   'region': buffered_extent,   'dimensions': 600,   'framesPerSecond': 1.5 };</p> <p>var text = require('users/gena/packages:text'); // Import gena's package which allows text overlay on image</p> <p>var annotations = [  {position: 'left', offset: '0.25%', margin: '0.25%', property: 'label', scale: 100} //large scale because image if of the whole world. Use smaller scale otherwise   ];</p> <p>function addText(image){   var image_0 = image.clip(districts.union());   var timeStamp = image.get('description'); // get the time stamp of each frame. This can be any string. Date, Years, Hours, etc.   var timeStamp_ = ee.String(timeStamp); //convert time stamp to string    var image_ = image_0.visualize(landSurfaceTemperatureVis).set({'label':timeStamp}); // set a property called label for each image   var annotated = text.annotateImage(image_, {}, extent, annotations); // create a new image with the label overlayed using gena's package   return annotated; }</p> <p>var AnnotatedCollectionWetSeason = WetSeasonMedianCollection.map(addText); //add time stamp to all images var AnnotatedCollectionDrySeason = DrySeasonMedianCollection.map(addText);</p> <p>print(ui.Thumbnail(AnnotatedCollectionWetSeason,  gifParams));</p> <p>var AnnotatedCollectionDrySeason = DrySeasonMedianCollection.map(addText);</p> <p>print(ui.Thumbnail(AnnotatedCollectionDrySeason,  gifParams));</p> <pre><code>\n&lt;p align=\"center\"&gt;\n      &lt;img src=\"./../rainy_season_20_years_modis.gif\" alt=\"Centered Image\"&gt;\n      &lt;br&gt;\n      &lt;i&gt;Rainy Season (Apr-Dec) MODIS Composites (20 years)&lt;/i&gt;\n      &lt;/p&gt;\n&lt;br&gt;\n\n&lt;p align=\"center\"&gt;\n      &lt;img src=\"./../dry_season_20_years_modis.gif\" alt=\"Centered Image\"&gt;\n      &lt;br&gt;\n      &lt;i&gt;Dry Season (Jan-Mar) MODIS Composites (20 years)&lt;/i&gt;\n      &lt;/p&gt;\n&lt;br&gt;\n\nFinally, we present our area of interest. For this we create a map of the regional location of our area of interest and another with the location within the country.  This is done with the help of the ui.Map object. Note how at the end we present the map with the location within the country with satellite images as background.\n\n```javascript linenums=\"1\"\n// ui.Map objects can be constructed. Here, a new map is declared.\nvar newMap = ui.Map({\n  center: {lat: 8, lon: -80, zoom: 5.5\n  },\n  style: {position: 'bottom-right', width: '400px'}\n});\n\nvar geomLayer = ui.Map.Layer(districts.union(), {color: 'red'}, 'Area of Interest');\nvar extentLayer = ui.Map.Layer(districts.bounds, {color:'red'}, 'Extent');\nnewMap.add(geomLayer);\nnewMap.add(extentLayer);\n\n// Add the newMap to the defaultMap;\nMap.add(newMap);\n\n// Other UI widgets can be added to ui.Map objects, for example labels:\ndefaultMap.add(ui.Label('Countrywide location', {position: 'bottom-left'}));\nnewMap.add(ui.Label('Regional Location', {position: 'bottom-left'}));\n\nMap.setControlVisibility({all: false});\nnewMap.setControlVisibility({all: false});\nMap.setOptions(\"SATELLITE\");\n</code></pre> <p> Regional and country-wide overview of our Area of Interest (AOI) </p> <p></p> <p>Google Earth Engine provides scientists, as well as anyone with a google account, the opportunity to perform spatial analysis, which can help us to assess the state of natural resources, demographic evolution and other geospatial phenomena.</p>"},{"location":"blog/posts/lst_modis/#conclusion","title":"Conclusion","text":"<p>In this blog post, we were able to see how to create a time series graph of temperature data from the MODIS Sensor for a geographic region that has undergone major geomorphological changes in recent years. This analysis could be done for a period of 20 years. In addition, these composites could be added in GIF format, and a regional and country level location map could also be added.</p>"},{"location":"blog/posts/nox_levels_in_panama/","title":"Monitoring Nitrogen Oxide Levels during the COVID 19 Lock-down, Panama City","text":"<p>From time to time I like new challenges in my field of work. From learning a new tool for geospatial analysis, explore a new dataset, improve my programming skills, dive deeper into the details of certain libraries, and so on.</p> <p>Today I would like to present a pipeline written for the Google Earth Engine JavaScript language interface. This pipeline aims to monitor nitrogen dioxide levels (a gas that has profound repercussions on public health, and whose levels are higher in urban than in rural areas), using the Sentinel-5 image collection. For this we will restrict our analysis to Panama City, the capital of my home country.</p> <p>Panama City is a city of just over 2 million inhabitants. It is an important banking and multi-modal transportation center thanks to the Panama Canal, which allows the transport of containers and ships transiting from the Atlantic to the Pacific Ocean and vice versa, an important global shipping network.</p> <p>However, people's lives during the COVID-19 pandemic changed dramatically when the first case was reported in early March 2020. These measures, according to this Wikipedia entry, comprised partial and total lockdown. </p> <p>This post is not to discuss the legitimacy, or effectiveness of these measures, but it allows us to visualize the changes in air quality, in situations as exceptional as a total quarantine, where the flow of land, air and sea traffic has been very low for some months.</p> <p>Below is the code put together, which works in the Google Earth Engine code editor. Our study area is the districts of the Province of Panama: San Miguelito, Arraij\u00e1n, and Panam\u00e1.</p> <p>These districts concentrate the highest population density, and are where most of the infrastructure, commercial and banking centers are located. The code should be self-explanatory, I have added comments on the different steps that are taken as it runs in Google Earth Engine. The result should be annual composites of Sentinel-5P Imagery for the years 2019-2022, as well as a chart of monthly nitrogen dioxide values from January 1, 2019 to November 2022.</p>"},{"location":"blog/posts/nox_levels_in_panama/#code","title":"Code","text":"Code ```javascript title=\"nitrogen_dioxide_monitoring.js\" linenums=\"1\" // Filtering Feature Collection to Area of Interest (AOI) var GAUL_country_boundaries = ee.FeatureCollection(\"FAO/GAUL/2015/level2\");  var Panama = GAUL_country_boundaries.filter(ee.Filter.eq('ADM1_NAME', 'Panam\u00e1')); print(Panama); Map.addLayer(Panama, {color: 'green'}, 'Panama Province'); var districts = ee.List(['Arraij\u00e1n', 'Panam\u00e1', 'San Miguelito']); var AOI = Panama.filter(ee.Filter.inList('ADM2_NAME', districts)); var AOI_ = AOI.union(); Map.addLayer(AOI_, {color: 'blue'}, 'Area of Interest');  // Setting the Map to the coordinates of one of our districts var centroid_coor =  AOI_.geometry().centroid().coordinates().getInfo(); var x = centroid_coor[0]; var y = centroid_coor[1]; Map.setCenter(x, y, 10);  // Setting visualization parameters var band_viz = {   min: 0,   max: 0.0002,    palette: ['white', 'orange', 'red', 'cyan', 'purple', 'green'] };  // Setting the start and end date // and creating the list of month and dates var date_start = ee.Date('2020-01-01'); var date_end= ee.Date('2022-12-31');  var months = ee.List.sequence(1, 12);//separate by years var years = ee.List.sequence(date_start.advance(-1,\"year\")                                        .get(\"year\"),                              date_end.get(\"year\"));  // Creating the image composites (monthly time series) // of Sentinel-5P tropospheric NO2 density var year_composite = years.map(function(y){   return months.map(function(m){     return ee.ImageCollection('COPERNICUS/S5P/OFFL/L3_NO2')             .select('tropospheric_NO2_column_number_density')             .filter(ee.Filter.calendarRange(y, y,'year'))             .filter(ee.Filter.calendarRange(m, m,'month'))             .median()             .set('year',y)             .set('month', m)             .clip(AOI_); })});  function decomposeList(l) {   return ee.ImageCollection.fromImages(l).toList(12); }  var list_imgs = year_composite.map(decomposeList).flatten();  // Setting as index the year and month  // of the layer being created function renameImages(img){   var img_1 = ee.Image(img);   var value = ee.Number(img_1.get('year')).format('%04d')               .cat('_').cat(ee.Number(img_1.get('month')).format('%02d'));   var img_2 = img_1.set('system:index', value, 'system:id', value);   return img_2; }  var list_imgs_renamed = list_imgs.map(renameImages);  var img_collection = ee.ImageCollection.fromImages(list_imgs_renamed);  // Create time lapse  var text = require('users/gena/packages:text'); // Import gena's package which allows text overlay on image  var annotations = [  {position: 'left', offset: '0.25%', margin: '0.25%', property: 'label', scale: 1000} //large scale because image if of the whole world. Use smaller scale otherwise   ];  function addText(image){   var timeStamp = image.id();   var image_ = image.visualize(band_viz).set({'label':timeStamp}); // set a property called label for each image   var annotated = text.annotateImage(image_, {}, AOI_.geometry(), annotations); // create a new image with the label overlayed using gena's package   return annotated; }  var extent = AOI_.geometry().bounds();  var buffered_extent = extent.buffer(ee.Number(10000).sqrt().divide(2), 1).bounds();  // Define GIF visualization parameters. var gifParams = {   'region': buffered_extent,   'dimensions': 600,   //'crs': 'EPSG:3857',   'framesPerSecond': 1.5 };  var annotated_collection = img_collection.map(addText);   // Print the GIF URL to the console. print(ui.Thumbnail(annotated_collection, gifParams)); ui.Thumbnail(annotated_collection, gifParams);  // Define the chart and print it to the console. var chart =     ui.Chart.image         .seriesByRegion({           imageCollection: img_collection,           band: 'tropospheric_NO2_column_number_density',           regions: AOI_,           reducer: ee.Reducer.mean(),           scale: 500,           seriesProperty: 'label',           xProperty: 'system:id'         })         .setOptions({           title: 'tropospheric NO2 column number density Years 2019-2022',           hAxis: {title: 'Date', titleTextStyle: {italic: false, bold: true},                    format: 'short'           },           vAxis: {             title: 'NOx \u00b5mol/m2',             titleTextStyle: {italic: false, bold: true},           },           lineWidth: 3,         });  //print(chart);  print(img_collection);  // Adding yearly composites  var imgs_2019 = img_collection.filter(ee.Filter.eq('year', 2019));  Map.addLayer(imgs_2019.mean(), band_viz, 'S5P N02_2019');  var imgs_2020 = img_collection.filter(ee.Filter.eq('year', 2020));  Map.addLayer(imgs_2020.mean(), band_viz, 'S5P N02_2020');  var imgs_2021 = img_collection.filter(ee.Filter.eq('year', 2021));  Map.addLayer(imgs_2021.mean(), band_viz, 'S5P N02_2021');  var imgs_2022 = img_collection.filter(ee.Filter.eq('year', 2022));  Map.addLayer(imgs_2022.mean(), band_viz, 'S5P N02_2022'); ```"},{"location":"blog/posts/nox_levels_in_panama/#output","title":"Output","text":"<p>Below is an image of the annual series of sentinel-5p images. These are the per-pixel average of these images for the years 2019-2022.</p> <p> </p> <p>Nitrogen Dioxide tropospheric column - Panama City - 2019-2022</p> <p> </p>"},{"location":"blog/posts/nox_levels_in_panama/#conclusion","title":"Conclusion","text":"<p>As can be seen, nitrogen dioxide concentrations vary from month to month. The dry season months (January to March, which are characterized by an increase in air velocity), have lower nitrogen dioxide concentrations than the rainy season months (April to December). In the year 2020 we see that the lowest and the highest nitrogen dioxide concentration were smaller compared to the previous and next year peak values. This may be attributed to lower vehicular traffic and population mobilization due to restrictions on citizenship to prevent the spread of the corona virus. During these months in some parts of the world a change in air quality could be evidenced. This was much more palpable in areas such as in China, where a similar analysis was made, yielding interesting results.</p> <p>It was very interesting to see how the environment has the resilience to regenerate itself from anthropocentric activities. In some latitudes of our planet, some wild animals started to be sighted in areas of high human disturbance, oceans started to regenerate as maritime traffic decreased, and people were able to have a better view of the surroundings of cities that are usually full of smog.</p> <p>The bad news is that all of this was made possible by strict restrictions due to a pandemic of global proportions, which paralyzed or affected our daily activities, and not by governmental interest or initiative to protect the environment in which we live.</p> <p>The good thing is that it makes us think about our place on this planet, and what we can do to make it a better place to live, both for ourselves and for other living things.</p> <p>Maybe that purchase or trip we want to make is not so important after all?</p>"},{"location":"blog/posts/refactoring_with_chat_gpt/","title":"Being kind with my future self, using Chat-GPT to explain my past code.","text":"<p>Lately, there's been a lot of talk about AI stealing our jobs as software developers. However, I prefer to see it as a tool that takes care of the boring stuff, freeing us up to focus on the more exciting aspects of our work. AI can handle tasks like dealing with documentation, fixing code, coming up with test ideas, and explaining code, allowing us to spend more time understanding what users really need and finding creative solutions. </p> <p>So, in today's blog post, I wanted to try something I've been meaning to do for a while. I'll put Chat-GPT to the test and use it to explain a code I wrote a couple of years ago. I'll also use some prompts to make the code even better, and improve its overall design and structure. Let's go.</p>"},{"location":"blog/posts/refactoring_with_chat_gpt/#first-code-snippets-i-was-creating-test-raster-files","title":"First code snippets: I was creating test raster files.","text":"<p>I have in an old repo, the following code. I think I used it to create a very simple raster in GeoTiff format for testing purposes.</p> Code ```python linenums=\"1\" #!/usr/bin/env python3  from osgeo import gdal  import numpy as np  from osgeo import osr import os   # Contants for file creation  dtype = gdal.GDT_Byte driver_name = \"GTiff\" geotransform = [300000, 10, 0, 1000020, 0, -10] x_size = 5 y_size = 5  def create_value_raster(filename):      \"\"\"Creates a test raster file\"\"\"      driver = gdal.GetDriverByName(driver_name)     dst_ds = driver.Create(filename, xsize = x_size, ysize= y_size,                             bands = 1, eType= dtype)     dst_ds.SetGeoTransform(geotransform)     srs = osr.SpatialReference()     srs.SetUTM(17, 1)     srs.SetWellKnownGeogCS(\"WGS84\")     dst_ds.SetProjection(srs.ExportToWkt())     array = np.array([[ x +1 for x in range(x_size)]\\                     for x in range(y_size)])     dst_ds.GetRasterBand(1).WriteArray(array)      dst_ds = None  def create_mask_raster(filename):       driver = gdal.GetDriverByName(driver_name)     dst_ds = driver.Create(filename, xsize = 5, ysize = 5,                             bands = 1, eType= dtype)     dst_ds.SetGeoTransform(geotransform)     srs = osr.SpatialReference()     srs.SetUTM(17, 1)     srs.SetWellKnownGeogCS(\"WGS84\")     dst_ds.SetProjection(srs.ExportToWkt())     array = np.array([[ 101, 101, 0, 0, 0],             [101, 101, 0, 202, 202],             [101, 101, 0, 202, 202],             [0, 0, 0, 0, 0],             [0, 0, 0, 0, 0],])     dst_ds.GetRasterBand(1).WriteArray(array)      dst_ds = None   def main():       try:          os.makedirs(\"output\")      except Exception as e:         print(e)       create_value_raster(\"output\" + \"/\" + \"value_raster.tif\")     create_mask_raster(\"output\" + \"/\" + \"mask_raster.tif\")   if __name__ == \"__main__\":      main()  <pre><code>&lt;/details&gt;\n\nThe code does its work, however there are things that I could improve. Those improvements come from my future self (that happens all the time, I revisit some code I wrote 5 years ago, and I can only cringe).\n\nNow, the time to ask the first question to Chat-GPT has come. In the following snippet you can find the nice question I just asked (I am always polite and try to do it even with advanced language processing systems... who knows maybe they are concious ;o) ):\n\n&lt;p align=\"center\"&gt;\n      &lt;img src=\"./../chat_gpt_1_question.png\" alt=\"Centered Image\"&gt;\n      &lt;br&gt;\n&lt;/p&gt;\n\nAnd of course... it did it. And the answer is incredibly accurate, detailed and well documented.\n\n&lt;details&gt;\n    &lt;summary&gt;Code&lt;/summary&gt;\n```python linenums=\"1\" \n#!/usr/bin/env python3\n\nfrom osgeo import gdal\nimport numpy as np\nfrom osgeo import osr\nimport os\n</code></pre> <p>This code imports necessary modules from the osgeo package, including gdal for geospatial data processing, osr for spatial reference system operations, and the standard os module for working with the operating system.</p> Code ```python linenums=\"1\" dtype = gdal.GDT_Byte driver_name = \"GTiff\" geotransform = [300000, 10, 0, 1000020, 0, -10] x_size = 5 y_size = 5  <pre><code>&lt;/details&gt;\n\nNext, some constants are defined:\n\n* dtype represents the data type of the raster, set to gdal.GDT_Byte.\n\n* driver_name specifies the desired driver for creating the raster files, in this case, \"GTiff\" for GeoTIFF format.\n\n* geotransform defines the geotransform parameters that describe the position and resolution of the raster data.\n\n* x_size and y_size indicate the dimensions (width and height) of the raster.\n\n&lt;details&gt;\n&lt;summary&gt;Code&lt;/summary&gt;\n```python linenums=\"1\"\ndef create_value_raster(filename):\n    \"\"\"Creates a test raster file\"\"\"\n    driver = gdal.GetDriverByName(driver_name)\n    dst_ds = driver.Create(filename, xsize=x_size, ysize=y_size, bands=1, eType=dtype)\n    dst_ds.SetGeoTransform(geotransform)\n    srs = osr.SpatialReference()\n    srs.SetUTM(17, 1)\n    srs.SetWellKnownGeogCS(\"WGS84\")\n    dst_ds.SetProjection(srs.ExportToWkt())\n    array = np.array([[x + 1 for x in range(x_size)] for x in range(y_size)])\n    dst_ds.GetRasterBand(1).WriteArray(array)\n    dst_ds = None\n</code></pre> <p>The create_value_raster function creates a test raster file with a filename provided as an argument. It uses the GDAL driver to create the raster file, setting its dimensions, number of bands, data type, geotransform, and spatial reference information. It then generates an array with increasing values and writes it to the raster band using WriteArray.</p> Code ```python linenums=\"1\" def create_mask_raster(filename):     driver = gdal.GetDriverByName(driver_name)     dst_ds = driver.Create(filename, xsize=5, ysize=5, bands=1, eType=dtype)     dst_ds.SetGeoTransform(geotransform)     srs = osr.SpatialReference()     srs.SetUTM(17, 1)     srs.SetWellKnownGeogCS(\"WGS84\")     dst_ds.SetProjection(srs.ExportToWkt())     array = np.array([[101, 101, 0, 0, 0],                       [101, 101, 0, 202, 202],                       [101, 101, 0, 202, 202],                       [0, 0, 0, 0, 0],                       [0, 0, 0, 0, 0]])     dst_ds.GetRasterBand(1).WriteArray(array)     dst_ds = None     ```  <p>The create_mask_raster function is similar to create_value_raster but generates a mask raster file with different values.</p> Code ```python linenums=\"1\" def main():     try:         os.makedirs(\"output\")     except Exception as e:         print(e)     create_value_raster(\"output\" + \"/\" + \"value_raster.tif\")     create_mask_raster(\"output\" + \"/\" + \"mask_raster.tif\")  <pre><code>&lt;/details&gt;\n\nThe main function is the entry point of the script. It attempts to create an \"output\" directory using os.makedirs. If the directory already exists, it will raise an exception which is printed to the console. Then, it calls the create_value_raster and create_mask_raster functions to create the value and mask raster files within the \"output\" directory.\n\n&lt;details&gt;\n&lt;summary&gt;Code&lt;/summary&gt;\n```python linenums=\"1\"\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Finally, if name == \"main\": ensures that the main function is executed only when the script is run directly, not when imported as a module.</p> <p>Usefulness: This code is useful for generating test raster files for geospatial data processing tasks. It showcases the use of the GDAL library to create raster files with specific dimensions, data types, geotransform parameters, and spatial reference information. The generated raster files can be used as sample data for testing and developing algorithms, models, or applications that work with geospatial data.</p>"},{"location":"blog/posts/refactoring_with_chat_gpt/#improving-the-code","title":"Improving the code","text":"<p>Now I would like to introduce some improvements in my code. I would like to introduce some type declarations for the functions, and also a nicely formatted docstring with parameters and return values specified. Let's do it.</p> <p> </p> Code ```python linenums=\"1\" #!/usr/bin/env python3  from osgeo import gdal import numpy as np from osgeo import osr import os  # Constants for file creation dtype: int = gdal.GDT_Byte driver_name: str = \"GTiff\" geotransform: list[float] = [300000, 10, 0, 1000020, 0, -10] x_size: int = 5 y_size: int = 5   def create_value_raster(filename: str) -&gt; None:     \"\"\"     Creates a test raster file.      Args:         filename (str): The name of the output raster file.      Returns:         None     \"\"\"     driver: gdal.Driver = gdal.GetDriverByName(driver_name)     dst_ds: gdal.Dataset = driver.Create(filename, xsize=x_size, ysize=y_size, bands=1, eType=dtype)     dst_ds.SetGeoTransform(geotransform)     srs: osr.SpatialReference = osr.SpatialReference()     srs.SetUTM(17, 1)     srs.SetWellKnownGeogCS(\"WGS84\")     dst_ds.SetProjection(srs.ExportToWkt())     array: np.ndarray = np.array([[x + 1 for x in range(x_size)] for x in range(y_size)])     dst_ds.GetRasterBand(1).WriteArray(array)     dst_ds = None   def create_mask_raster(filename: str) -&gt; None:     \"\"\"     Creates a mask raster file.      Args:         filename (str): The name of the output raster file.      Returns:         None     \"\"\"     driver: gdal.Driver = gdal.GetDriverByName(driver_name)     dst_ds: gdal.Dataset = driver.Create(filename, xsize=5, ysize=5, bands=1, eType=dtype)     dst_ds.SetGeoTransform(geotransform)     srs: osr.SpatialReference = osr.SpatialReference()     srs.SetUTM(17, 1)     srs.SetWellKnownGeogCS(\"WGS84\")     dst_ds.SetProjection(srs.ExportToWkt())     array: np.ndarray = np.array(         [             [101, 101, 0, 0, 0],             [101, 101, 0, 202, 202],             [101, 101, 0, 202, 202],             [0, 0, 0, 0, 0],             [0, 0, 0, 0, 0],         ]     )     dst_ds.GetRasterBand(1).WriteArray(array)     dst_ds = None   def main() -&gt; None:     \"\"\"     Main function that creates the value and mask raster files.      Returns:         None     \"\"\"     try:         os.makedirs(\"output\")     except Exception as e:         print(e)     create_value_raster(\"output\" + \"/\" + \"value_raster.tif\")     create_mask_raster(\"output\" + \"/\" + \"mask_raster.tif\")   if __name__ == \"__main__\":     main()  <pre><code>&lt;/details&gt;\n\nOf course the code now looks better with type declarations and a docstring showing the arguments and\n\ntheir type, as well as the return values. \n\nLet's see if it can make some changes to a test suite I created within the directory. By now, the test suit runs correctly, however I would like to test Chat-GPT to introduce some changes. \n\n## Test Code\n\nThe next code snippet is the contents of a file called text_pixel_stats.py:\n\n&lt;details&gt;\n&lt;summary&gt;Code&lt;/summary&gt;\n```python linenums=\"1\"\n#!/usr/bin/env python3\n\nimport unittest\nimport numpy as np \nfrom osgeo import gdal\nimport subprocess\nimport pandas as pd\n\n\ndef return_index_2D_array(arr, val): \n\n    \"\"\"Returns the index for valid data in array,\n    as a lists of tuple, with every tuple\n    containing the valid coordinate positions\n    in image for every pixel\"\"\" \n\n    result =  np.where(arr != val)\n    rows = result[0].astype(\"uint8\")\n    cols = result[1].astype(\"uint8\")\n    listOfCoordinates = list(zip(rows, cols))\n    return listOfCoordinates\n\ndef return_image_coordinate(x, y, gt):\n\n    \"\"\"\n    From pixel coordinates (x,y) returns\n    the image coordinate. It needs the\n    Geotransform parameters as list (gt)\n    \"\"\"\n    xoffset = gt[0]\n    px_w = gt[1]\n    rot1 = gt[2]\n    yoffset = gt[3]\n    rot2 = gt[4]\n    px_h = gt[5]\n\n    xgeo = px_w * x + rot1 * y + xoffset\n    ygeo = rot2 * x + px_h * y + yoffset\n    xgeo += px_w / 2.0\n    ygeo += px_h / 2\n\n    return xgeo, ygeo \n\n\nclass TestPixelStats(unittest.TestCase):\n\n    def masking_values(self, arr1, pixel_val):\n\n        \"\"\"Creates a bool mask, related to invalid\n        pixels in an array. True belong a valid\n        pixels, where 'pixel_value' is not found\"\"\"\n\n        mask = ((arr1 != pixel_val))\n\n        return mask \n\n\n    def change_dtype_array(self, arr, dtype): \n\n        \"\"\"Changes the data type of array\"\"\"\n        return arr.astype(dtype)\n\n\n    def return_index_2D_array(self, arr, val): \n\n        \"\"\"Returns the index for valid data in array,\n        as a lists of tuple, with every tuple\n        containing the valid coordinate positions\n        in image for every pixel\"\"\" \n\n        result =  np.where(arr != val)\n        rows = result[0].astype(\"uint8\")\n        cols = result[1].astype(\"uint8\")\n        listOfCoordinates = list(zip(rows, cols))\n        return listOfCoordinates\n\n    def return_image_coordinate(self, x, y, gt):\n\n        \"\"\"\n        From pixel coordinates (x,y) returns\n        the image coordinate. It needs the\n        Geotransform parameters as list (gt)\n        \"\"\"\n        xoffset = gt[0]\n        px_w = gt[1]\n        rot1 = gt[2]\n        yoffset = gt[3]\n        rot2 = gt[4]\n        px_h = gt[5]\n\n        xgeo = px_w * x + rot1 * y + xoffset\n        ygeo = rot2 * x + px_h * y + yoffset\n        xgeo += px_w / 2.0\n        ygeo += px_h / 2\n\n        return xgeo, ygeo \n\n\n    def setUp(self): \n\n        \"\"\" The setup files to run this tests are\n        located in the output folder, and they are\n        created with the create_test_files.py script\n        \"\"\"\n\n        self.values_path = \"output/value_raster.tif\" \n        self.mask_path = \"output/mask_raster.tif\"\n\n        self.in_ds_values = gdal.Open(self.values_path)\n        self.in_ds_mask = gdal.Open(self.mask_path)\n\n        self.values_arr = np.array(self.in_ds_values.GetRasterBand(1)\\\n                        .ReadAsArray()) \n        self.mask_arr = np.array(self.in_ds_mask.GetRasterBand(1).\\\n                        ReadAsArray())\n\n\n    def test_masking_values(self):\n\n        \"\"\"Tests if after creating a boolean mask\n        with True values returned where valid data\n        are located, and False whenever the invalid\n        value is found in the array. In this case\n        we take 0 as the invalid value\"\"\"\n\n        mask = self.masking_values(self.mask_arr, 0)\n        data = np.where(mask == False, np.nan, self.values_arr)\n        data = self.change_dtype_array(data, \"uint8\")\n        should_be = np.array([[1, 2, np.nan, np.nan, np.nan],\n                            [1, 2, np.nan, 4, 5],\n                            [1, 2, np.nan, 4, 5],\n                            [np.nan, np.nan, np.nan, np.nan, np.nan],\n                            [np.nan, np.nan, np.nan, np.nan, np.nan]])\n        should_be = self.change_dtype_array(should_be, \"uint8\") \n        self.assertEqual(data.tolist(), should_be.tolist())\n\n    def testing_return_index_2D_array(self): \n\n        \"\"\"Tests if position coordinates in image are returned\n        from a value array. Valid pixels are the ones different\n        of 0\"\"\"\n\n        mask = self.masking_values(self.mask_arr, 0) \n        data = np.where(mask == False, 0, self.values_arr)\n        data = self.change_dtype_array(data, \"uint8\")\n        index_valid_data = self.return_index_2D_array(data, 0)\n        list_of_coordinates = [(0,0), (0,1),\n                                (1,0), (1,1),(1,3), (1,4),\n                                (2,0), (2,1),(2,3), (2,4)]\n        self.assertEqual(index_valid_data, list_of_coordinates)\n\n\n    def testing_return_pos_coordinates_(self):\n\n        \"\"\"Tests if position coordinates for  a pixel position\n        on an image are returned, for valid data. In this case \n        no valid data is 0\"\"\"\n\n        mask = self.masking_values(self.mask_arr, 0) \n        data = np.where(mask == False, 0, self.values_arr)\n        data = self.change_dtype_array(data, \"uint8\")\n        index_valid_data = self.return_index_2D_array(data, 0)\n        list_of_coordinates = [(0,0), (0,1),\n                                (1,0), (1,1),(1,3), (1,4),\n                                (2,0), (2,1),(2,3), (2,4)]\n        gt = self.in_ds_values.GetGeoTransform() \n        test_posx = list_of_coordinates[0][0]\n        test_posy = list_of_coordinates[0][1]\n        geo_posx, geo_posy = self.return_image_coordinate(test_posx,\\\n                                                        test_posy,\\\n                                                        gt)\n        self.assertEqual(geo_posx, 300005)\n        self.assertEqual(geo_posy, 1000015)\n\n\nclass TestPixelStats(unittest.TestCase):\n\n    def testing_workflow(self): \n\n        values_ds = gdal.Open(\"output/value_raster.tif\")\n        mask_ds = gdal.Open(\"output/mask_raster.tif\")\n\n        ## Masking out valid data from mask raster \n        ## output/mask_raster.tif plays the role that \n        ## the rasterized version of the vector with \n        ## the \"burned\" class column, that will become\n        ## the raster values \n\n        print(\"-- Reading arrays for Values, FID and Proximity --\")\n        values_arr = np.array(values_ds.GetRasterBand(1)\\\n                        .ReadAsArray())\n        mask_arr_original = np.array(mask_ds.GetRasterBand(1)\\\n                        .ReadAsArray())\n\n        print(\"-- Extracting only valid data and fid --\")\n        values_arr = values_arr[mask_arr_original != 0] \n        print(values_arr.shape)\n        mask_arr = mask_arr_original[mask_arr_original != 0]\n        print(mask_arr.shape)\n\n        print(\"-- Getting xcoor and ycoor for pixels --\")\n        gt = mask_ds.GetGeoTransform() \n        index_valid_data = return_index_2D_array(mask_arr_original, 0)\n        print(index_valid_data) \n        coor_valid_data = np.array([return_image_coordinate(x[0], x[1], gt) for x in index_valid_data])\n        x_coor_ = np.array([item[0] for item in coor_valid_data.tolist()])\n        y_coor_ = np.array([item[1] for item in coor_valid_data.tolist()])\n\n        print(x_coor_)\n        print(y_coor_)\n\n        Data = pd.DataFrame(values_arr, columns = [\"TF_VALUE\"])\n        Data[\"FID\"] = mask_arr\n        Data[\"X_coor\"] = x_coor_\n        Data[\"Y_coor\"] = y_coor_\n        print(Data)\n\n\nif __name__ == '__main__':\n    unittest.main()\n</code></pre> <p>Even though the function works, there is a couple of things that I don't like about my past code. First I declared some functions, that I copy 1:1 as methods within the Test Suite. I would like to get rid of these code duplication. </p> <p> </p> <p>The following is the code generated by the prompt:</p> Code ```python linenums=\"1\" #!/usr/bin/env python3  import unittest import numpy as np from osgeo import gdal import subprocess import pandas as pd   def return_index_2D_array(arr, val):     \"\"\"Returns the index for valid data in an array,     as a list of tuples, with each tuple containing the     coordinates of valid data in the image for each pixel\"\"\"     result = np.where(arr != val)     rows = result[0].astype(\"uint8\")     cols = result[1].astype(\"uint8\")     listOfCoordinates = list(zip(rows, cols))     return listOfCoordinates   def return_image_coordinate(x, y, gt):     \"\"\"     From pixel coordinates (x,y), returns     the image coordinates. It requires the     Geotransform parameters as a list (gt).     \"\"\"     xoffset = gt[0]     px_w = gt[1]     rot1 = gt[2]     yoffset = gt[3]     rot2 = gt[4]     px_h = gt[5]      xgeo = px_w * x + rot1 * y + xoffset     ygeo = rot2 * x + px_h * y + yoffset     xgeo += px_w / 2.0     ygeo += px_h / 2      return xgeo, ygeo   class TestPixelStats(unittest.TestCase):     def masking_values(self, arr1, pixel_val):         \"\"\"Creates a boolean mask related to invalid         pixels in an array. True belongs to valid         pixels, where 'pixel_value' is not found\"\"\"         mask = arr1 != pixel_val         return mask      def change_dtype_array(self, arr, dtype):         \"\"\"Changes the data type of an array\"\"\"         return arr.astype(dtype)      def setUp(self):         \"\"\"The setup files to run these tests are         located in the output folder and are created         with the create_test_files.py script\"\"\"         self.values_path = \"output/value_raster.tif\"         self.mask_path = \"output/mask_raster.tif\"          self.in_ds_values = gdal.Open(self.values_path)         self.in_ds_mask = gdal.Open(self.mask_path)          self.values_arr = np.array(self.in_ds_values.GetRasterBand(1).ReadAsArray())         self.mask_arr = np.array(self.in_ds_mask.GetRasterBand(1).ReadAsArray())      def test_masking_values(self):         \"\"\"Tests if after creating a boolean mask         with True values returned where valid data         are located, and False whenever the invalid         value is found in the array. In this case,         we take 0 as the invalid value\"\"\"         mask = self.masking_values(self.mask_arr, 0)         data = np.where(mask == False, np.nan, self.values_arr)         data = self.change_dtype_array(data, \"uint8\")         should_be = np.array(             [                 [1, 2, np.nan, np.nan, np.nan],                 [1, 2, np.nan, 4, 5],                 [1, 2, np.nan, 4, 5],                 [np.nan, np.nan, np.nan, np.nan, np.nan],                 [np.nan, np.nan, np.nan, np.nan, np.nan],             ]         )         should_be = self.change_dtype_array(should_be, \"uint8\")         self.assertEqual(data.tolist(), should_be.tolist())      def testing_return_index_2D_array(self):         \"\"\"Tests if position coordinates in the image are returned         from a value array. Valid pixels are the ones different         from 0\"\"\"         mask = self.masking_values(self.mask_arr, 0)         data = np.where(mask == False, 0, self.values_arr)         data = self.change_dtype_array(data, \"uint8\")         index_valid_data = return_index_2D_array(data, 0)         list_of_coordinates = [             (0, 0),             (0, 1),             (1, 0),             (1, 1),             (1, 3),             (1, 4),             (2, 0),             (2, 1),             (2, 3),             (2, 4),         ]         self.assertEqual(index_valid_data, list_of_coordinates)      def testing_return_pos_coordinates(self):         \"\"\"Tests if position coordinates for a pixel position         on an image are returned for valid data. In this case,         no valid data is 0\"\"\"         mask = self.masking_values(self.mask_arr, 0)         data = np.where(mask == False, 0, self.values_arr)         data = self.change_dtype_array(data, \"uint8\")         index_valid_data = return_index_2D_array(data, 0)         list_of_coordinates = [             (0, 0),             (0, 1),             (1, 0),             (1, 1),             (1, 3),             (1, 4),             (2, 0),             (2, 1),             (2, 3),             (2, 4),         ]         gt = self.in_ds_values.GetGeoTransform()         test_posx = list_of_coordinates[0][0]         test_posy = list_of_coordinates[0][1]         geo_posx, geo_posy = return_image_coordinate(test_posx, test_posy, gt)         self.assertEqual(geo_posx, 300005)         self.assertEqual(geo_posy, 1000015)   if __name__ == \"__main__\":     unittest.main()  <pre><code>&lt;/details&gt;\n\nAnd the tests still run:\n\n!!! success\n    ```linux\n    $ python -m unittest\n    ...\n    ----------------------------------------------------------------------\n    Ran 3 tests in 0.010s\n    ```\n\n## Refactoring the test class\n\nAnother improvement we can introduce is to remove methods, and make them functions outside of the Test Class body. Let's do it.\n\n&lt;p align=\"center\"&gt;\n      &lt;img src=\"./../chat_gpt_4_question.png\" alt=\"Centered Image\"&gt;\n      &lt;br&gt;\n&lt;/p&gt;\n\n&lt;details&gt;\n&lt;summary&gt;Code&lt;/summary&gt;\n```python linenums=\"1\"\n#!/usr/bin/env python3\n\nimport unittest\nimport numpy as np\nfrom osgeo import gdal\nimport subprocess\nimport pandas as pd\n\n\ndef masking_values(arr1, pixel_val):\n    \"\"\"Creates a boolean mask related to invalid\n    pixels in an array. True belongs to valid\n    pixels, where 'pixel_value' is not found\"\"\"\n    mask = arr1 != pixel_val\n    return mask\n\n\ndef change_dtype_array(arr, dtype):\n    \"\"\"Changes the data type of an array\"\"\"\n    return arr.astype(dtype)\n\n\ndef return_index_2D_array(arr, val):\n    \"\"\"Returns the index for valid data in an array,\n    as a list of tuples, with each tuple containing the\n    coordinates of valid data in the image for each pixel\"\"\"\n    result = np.where(arr != val)\n    rows = result[0].astype(\"uint8\")\n    cols = result[1].astype(\"uint8\")\n    listOfCoordinates = list(zip(rows, cols))\n    return listOfCoordinates\n\n\ndef return_image_coordinate(x, y, gt):\n    \"\"\"\n    From pixel coordinates (x,y), returns\n    the image coordinates. It requires the\n    Geotransform parameters as a list (gt).\n    \"\"\"\n    xoffset = gt[0]\n    px_w = gt[1]\n    rot1 = gt[2]\n    yoffset = gt[3]\n    rot2 = gt[4]\n    px_h = gt[5]\n\n    xgeo = px_w * x + rot1 * y + xoffset\n    ygeo = rot2 * x + px_h * y + yoffset\n    xgeo += px_w / 2.0\n    ygeo += px_h / 2\n\n    return xgeo, ygeo\n\n\nclass TestPixelStats(unittest.TestCase):\n    def setUp(self):\n        \"\"\"The setup files to run these tests are\n        located in the output folder and are created\n        with the create_test_files.py script\"\"\"\n        self.values_path = \"output/value_raster.tif\"\n        self.mask_path = \"output/mask_raster.tif\"\n\n        self.in_ds_values = gdal.Open(self.values_path)\n        self.in_ds_mask = gdal.Open(self.mask_path)\n\n        self.values_arr = np.array(self.in_ds_values.GetRasterBand(1).ReadAsArray())\n        self.mask_arr = np.array(self.in_ds_mask.GetRasterBand(1).ReadAsArray())\n\n    def test_masking_values(self):\n        \"\"\"Tests if after creating a boolean mask\n        with True values returned where valid data\n        are located, and False whenever the invalid\n        value is found in the array. In this case,\n        we take 0 as the invalid value\"\"\"\n        mask = masking_values(self.mask_arr, 0)\n        data = np.where(mask == False, np.nan, self.values_arr)\n        data = change_dtype_array(data, \"uint8\")\n        should_be = np.array(\n            [\n                [1, 2, np.nan, np.nan, np.nan],\n                [1, 2, np.nan, 4, 5],\n                [1, 2, np.nan, 4, 5],\n                [np.nan, np.nan, np.nan, np.nan, np.nan],\n                [np.nan, np.nan, np.nan, np.nan, np.nan],\n            ]\n        )\n        should_be = change_dtype_array(should_be, \"uint8\")\n        self.assertEqual(data.tolist(), should_be.tolist())\n\n    def testing_return_index_2D_array(self):\n        \"\"\"Tests if position coordinates in the image are returned\n        from a value array. Valid pixels are the ones different\n        from 0\"\"\"\n        mask = masking_values(self.mask_arr, 0)\n        data = np.where(mask == False, 0, self.values_arr)\n        data = change_dtype_array(data, \"uint8\")\n        index_valid_data = return_index_2D_array(data, 0)\n        list_of_coordinates = [\n            (0, 0),\n            (0, 1),\n            (1, 0),\n            (1, 1),\n            (1, 3),\n            (1, 4),\n            (2, 0),\n            (2, 1),\n            (2, 3),\n            (2, 4),\n        ]\n        self.assertEqual(index_valid_data, list_of_coordinates)\n\n    def testing_return_pos_coordinates(self):\n        \"\"\"Tests if position coordinates for a pixel position\n        on an image are returned for valid data. In this case,\n        no valid data is 0\"\"\"\n        mask = masking_values(self.mask_arr, 0)\n        data = np.where(mask == False, 0, self.values_arr)\n        data = change_dtype_array(data, \"uint8\")\n        index_valid_data = return_index_2D_array(data, 0)\n        list_of_coordinates = [\n            (0, 0),\n            (0, 1),\n            (1, 0),\n            (1, 1),\n            (1, 3),\n            (1, 4),\n            (2, 0),\n            (2, 1),\n            (2, 3),\n            (2, 4),\n        ]\n        gt = self.in_ds_values.GetGeoTransform()\n        test_posx = list_of_coordinates[0][0]\n        test_posy = list_of_coordinates[0][1]\n        geo_posx, geo_posy = return_image_coordinate(test_posx, test_posy, gt)\n        self.assertEqual(geo_posx, 300005)\n        self.assertEqual(geo_posy, 1000015)\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n</code></pre> <p>In this re-written version of the test suite by Chat-GPT, the masking_values and change_dtype_array functions are declared outside the TestPixelStats class and are utilized directly within the test methods.</p>"},{"location":"blog/posts/refactoring_with_chat_gpt/#what-if-pytest","title":"What if pytest?","text":"<p>My second improvement in the test suite is to change the unittest framework for the pytest framework. I will ask Chat-GPT to translate the unittest to a pytest, use fixtures to replace the setUp method, and finally do some more improvements like creating better docstrings for the functions, and giving better formatted docstrings. The reason behind changing to pytest is personal. Even though unittest is part of the standard library, I find pytest less boiler plate.</p> <p> </p> Code ```python linenums=\"1\" import pytest import numpy as np from osgeo import gdal from typing import List, Tuple   def masking_values(arr1: np.ndarray, pixel_val: int) -&gt; np.ndarray:     \"\"\"     Creates a boolean mask related to invalid pixels in an array.     True belongs to valid pixels, where 'pixel_value' is not found.     \"\"\"     mask = arr1 != pixel_val     return mask   def change_dtype_array(arr: np.ndarray, dtype: str) -&gt; np.ndarray:     \"\"\"Changes the data type of an array.\"\"\"     return arr.astype(dtype)   def return_index_2D_array(arr: np.ndarray, val: int) -&gt; List[Tuple[int, int]]:     \"\"\"     Returns the index for valid data in the array as a list of tuples.     Each tuple contains the coordinates of valid data in the image for each pixel.     \"\"\"     result = np.where(arr != val)     rows = result[0].astype(\"uint8\")     cols = result[1].astype(\"uint8\")     listOfCoordinates = list(zip(rows, cols))     return listOfCoordinates   def return_image_coordinate(x: int, y: int, gt: List[float]) -&gt; Tuple[float, float]:     \"\"\"     From pixel coordinates (x,y), returns the image coordinates.     It requires the Geotransform parameters as a list (gt).     \"\"\"     xoffset, px_w, rot1, yoffset, rot2, px_h = gt      xgeo = px_w * x + rot1 * y + xoffset     ygeo = rot2 * x + px_h * y + yoffset     xgeo += px_w / 2.0     ygeo += px_h / 2      return xgeo, ygeo   @pytest.fixture def test_data():     values_path = \"output/value_raster.tif\"     mask_path = \"output/mask_raster.tif\"     in_ds_values = gdal.Open(values_path)     in_ds_mask = gdal.Open(mask_path)     values_arr = np.array(in_ds_values.GetRasterBand(1).ReadAsArray())     mask_arr = np.array(in_ds_mask.GetRasterBand(1).ReadAsArray())     return values_arr, mask_arr   def test_masking_values(test_data):     \"\"\"Tests if after creating a boolean mask with True values returned where valid data     are located, and False whenever the invalid value is found in the array. In this case,     we take 0 as the invalid value.\"\"\"     values_arr, mask_arr = test_data     mask = masking_values(mask_arr, 0)     data = np.where(mask == False, np.nan, values_arr)     data = change_dtype_array(data, \"uint8\")     should_be = np.array(         [             [1, 2, np.nan, np.nan, np.nan],             [1, 2, np.nan, 4, 5],             [1, 2, np.nan, 4, 5],             [np.nan, np.nan, np.nan, np.nan, np.nan],             [np.nan, np.nan, np.nan, np.nan, np.nan],         ]     )     should_be = change_dtype_array(should_be, \"uint8\")     assert np.array_equal(data, should_be)   def test_return_index_2D_array(test_data):     \"\"\"Tests if position coordinates in the image are returned from a value array.     Valid pixels are the ones different from 0.\"\"\"     values_arr, mask_arr = test_data     mask = masking_values(mask_arr, 0)     data = np.where(mask == False, 0, values_arr)     data = change_dtype_array(data, \"uint8\")     index_valid_data = return_index_2D_array(data, 0)     list_of_coordinates = [         (0, 0),         (0, 1),         (1, 0),         (1, 1),         (1, 3),         (1, 4),         (2, 0),         (2, 1),         (2, 3),         (2, 4),     ]     assert index_valid_data == list_of_coordinates   def test_return_image_coordinate(test_data):     \"\"\"Tests if position coordinates for a pixel position on an image are returned     for valid data. In this case, no valid data is 0.\"\"\"     values_arr, mask_arr = test_data     mask = masking_values(mask_arr, 0)     data = np.where(mask == False, 0, values_arr)     data = change_dtype_array(data, \"uint8\")     index_valid_data = return_index_2D_array(data, 0)     list_of_coordinates = [         (0, 0),         (0, 1),         (1, 0),         (1, 1),         (1, 3),         (1, 4),         (2, 0),         (2, 1),         (2, 3),         (2, 4),     ]     gt = gdal.Open(\"output/value_raster.tif\").GetGeoTransform()     test_posx = list_of_coordinates[0][0]     test_posy = list_of_coordinates[0][1]     geo_posx, geo_posy = return_image_coordinate(test_posx, test_posy, gt)     assert geo_posx == 300005     assert geo_posy == 1000015 ```  <p>I ran the tests and the feedback is still positive. !!! success     ```linux     $ python -m pytest     =============================================================== test session starts ================================================================     platform win32 -- Python 3.10.4, pytest-7.2.0, pluggy-1.0.0     rootdir: C:\\Users\\almrog\\pixel_stats     plugins: anyio-3.6.2     collected 3 items</p> <pre><code>test_pixel_stats.py ...                                                                                                                       [100%]\n\n================================================================ 3 passed in 0.32s =================================================================\n```\n</code></pre> <p>In this version, the code uses the pytest framework and fixtures to replace the setUp method. The functions masking_values, change_dtype_array, return_index_2D_array, and return_image_coordinate are declared outside the test class and are utilized directly within the test functions. The code includes type hints and improved docstrings for better readability and clarity.</p>"},{"location":"blog/posts/refactoring_with_chat_gpt/#conclusion","title":"Conclusion","text":"<p>Chat-GPT (or advanced language processing systems) can indeed be intimidating for software developers. These systems not only provide code solutions but also offer explanations and improvements, almost automatically. However, just like any tool that facilitates work for professionals (such as chainsaws for forestry workers or cranes for construction workers), language processing systems that can translate ideas into code are useful if you have a solid understanding of your work, you know relevant concepts, and know what results you expect. In other words, you could eventually arrive at the same solution on your own, but it would undoubtedly take more time. At present, I am thrilled about these advancements that make our lives as programmers easier and allow us to focus on software design and delivering solutions to our clients.</p>"},{"location":"blog/posts/river_dam_el_valle/","title":"Landscape changes, my childhood, and the impact of man-made infrastructure","text":"<p>One of the privileges we have in our generation is to be able to see the earth from space. Thanks to satellite missions such as Sentinel 1, 2 and 3, as well as Landsat, we can have images of the earth's surface, which in favorable weather conditions (low cloud cover), we can see the earth in unprecedented spatial resolution, for license-free images. We can for example see details such as changes in forest cover, how cities are growing, and how constructions such as river dams change our landscape. This post is about the latter.</p> <p>A few years ago I went to the community of El Valle de Las Lomas. This small town, located about 15 minutes from the city of David, Chiriqu\u00ed, Republic of Panama, has a place in my heart. There I spent part of my summer vacations at my grandmother's house, and it was also the town where I had a lot of friends and family, with whom I played soccer and baseball in the afternoons.</p> <p>Before the COVID-19 pandemic I had the opportunity to visit this river, and was surprised to see that all that was left was a creek in what used to be a flowing river, where my father and brother would go to spend the occasional afternoon fishing.</p> <p>I was surprised by the great change in the scenery along some stretches of this river. Some stretches that used to be deep were now reduced to a small creek that could be crossed on foot without the water coming up to your knees. </p> <p>Perhaps the reason was the severe dry season that was hitting the area for those months. What cannot be denied is that for a community as small as El Valle de Las Lomas, having a project of this magnitude meant a big change in land use, which can be seen in the following series of images from the Landsat 7 mission. Here you can see the construction works in the late 2000s, to begin the 2010s with a reservoir and the necessary infrastructure for the power plant.</p> <p> </p> <p>No doubt this change in the landscape meant that many people gave up places where they used to spend happy afternoons with their families. While it is true that electricity generation is one of the priorities of our modern world, the search for clean, low-impact energy alternatives should be the gold standard in this regard. While I was still living in my homeland, I saw the back and forth between people for and against hydro-power projects, and of course, the positive and negative impacts were presented in a compelling way from both sides.</p> <p>In the next post, we will look at how satellite data can be used to observe changes over time in land surface temperature in this location since the construction of this hydroelectric plant. We know that the time series is not that dense, but we can derive interesting information about this. In the meantime, and if you like the animation I generated, you can visit the following link where you can see the JavaScript code to generate this animation in Google Earth Engine.</p>"},{"location":"blog/posts/statistics_with_SQL/","title":"Basic descriptive statistics using SQL","text":"<p>I have always had an admiration for ancient architecture. They are the remnants of ancestral cultures, and in them we can see the human need to create something lasting, according to the needs of that time, but with an impeccable beauty that still delights our eyes. The same feeling I also have for relatively old programming languages. Although I currently work mainly with the Python programming language, I sporadically venture into programming something simple in C. The latter also opened my eyes to many concepts that are unfortunately taken for granted when starting in the programming world with a high-level language such as Python, such as declaring type variables, the use of pointers or memory management. This year though, I am committed to improve my skills in the SQL language, and its PostGIS extension for geospatial analysis. Like C, SQL is a language with great relevance nowadays and which allows us to make database queries, generate statistical analysis, and organize our data. SQL stands the test of time, and it is really worth taking the time to learn it if you haven't given it a try yet.</p> <p>As you may recall from my previous post, I recently downloaded some shapefiles that I will be using in future side-projects. </p> <p>In this new blog we are going to perform some basic geospatial queries using PostgreSQL and its geospatial PostGIS extension.</p> <p>To start off, we are going to import the shapefiles into our database.</p>"},{"location":"blog/posts/statistics_with_SQL/#getting-our-data-in-a-local-database","title":"Getting our data in a local database","text":"<p>We start by ingesting our Shapefile in our Database. I am assuming that you already installed PosgreSQL, Pgadmin4 and have activated the POSTGIS extension. Otherwise here is a series of links that will help you to set up your system and have everything ready for the next exercises.</p> <p>To download PostgreSQL and PGAdmin</p> <ul> <li> <p>PostgreSQL: Windows installers</p> </li> <li> <p>Download pgadmin.org</p> </li> </ul> <p>How to create your first database schema</p> <ul> <li>Creating PostgreSQL Database - RapidMiner Documentation</li> </ul> <p>How to install PostGIS extension: </p> <ul> <li>Installation \u2014 Introduction to PostGIS</li> </ul> <p>After giving your password to access your database, start by collapsing the Servers Menu. You will find a list of the databases existing on your Server Group. As you can see I have a Database called postgres, which is the default database that will be existing when you opening your pgAdmin.</p> <p> </p> <p>With a right click go to the Create, Database\u2026 option.</p> <p> </p> <p>The following menu will be opened once you have selected the create database option. Here you will have to fill in the Database name field, which in this case I called \"Example-Brandenburg\" and the Owner postgres. Then click on Save.</p> <p> </p> <p>Right click on the Example-Brandenburg Icon (or whatever name you have given to your database), and go to the Query Tool option. This will allow us to query the database later, but for now we will use it to activate our PostGIS extension for this database.</p> <p> </p> <p> </p> <p>Again I repeat: I am assuming that you have already installed PostGIS on your computer. If so, just run CREATE postgis extension; and this will allow you to have all the geospatial analysis functionalities that PostGIS provides on your database.</p> <p> </p> <p>Once you have activated the PostGIS extension, we are going to import our Shapefile into our database as a table. For this, let's look for the PostGIS Bundle 3 for PostgreSQL application, which should come with your PostGIS installation.</p> <p> </p> <p>Once you click here, you will be taken to the PostGIS Shapefile Import/Export Manager, which will allow us to import our data in Shape format.</p> <p> </p> <p>Once here, click on View connection details to view the details of your database connection, make the appropriate changes and verify that you have access to your database by testing the connection. In my example I put my username, which I have left as postgres because was my default value. Then I put the password that I created for my database. In the field host, I set it as 'localhost', because I am working locally. The port in my database is 5432 which is without fear of being wrong also the default value that is given to the user when creating his first database, and finally I put the value of Example-Brandenburg, which is the name of the database that I just created in the previous steps.</p> <p> </p> <p>By pressing the OK button and if all goes well, you should receive a \"Connection succeeded\" notification, telling you that you have access to your database from the PostGIS Shapefile Import/Export Manager.</p> <p> </p> <p>Now click on the \"Add File\" button to search for the shapefile in your filesystem. Once found select it and click on the open button at the bottom right.</p> <p> </p> <p>After that click on the import button to start the import process to your database.</p> <p> </p> <p>Once the process is finished, collapse your database menu \"Example-Brandenburg\". You will see the menu tables in which you will find a new table with the name of the shapefile you just imported. The table spatial_ref_sys, is a table that is presented when you did the activation of the PostGIS extension in a previous step.</p> <p> </p> <p>By right clicking on your table you will find the menu where you will select the Query Tool option, to make a small test to our table in the database.</p> <p> </p> <p>Here we are going to make our first query with the following command:</p> <pre><code>SELECT * \nfrom antragsdaten_2022_antrag\n</code></pre> <p>Please enter this command in the Query Window. You will have the output in the Data Output tab on the result's window. </p> <p> </p> <p>Basically we are telling our database, please select all columns and all entries (rows) from the antragsdaten_2022_antrag table. </p> <p>The result will appear in our Data Output window, and as we can see, there is the series of rows and columns that make up all the records of that table, which are the records of the Shapefile that we imported with the PostGIS Import Export Manager. After these steps, now let's start with the most fun part from my point of view, making spatial queries with this database.</p>"},{"location":"blog/posts/statistics_with_SQL/#making-our-queries","title":"Making our queries","text":""},{"location":"blog/posts/statistics_with_SQL/#how-many-and-which-columns-does-this-table-contain","title":"How many and which columns does this table contain?","text":"<pre><code>SELECT *\n  FROM information_schema.columns\n WHERE table_schema = 'public'\n   AND table_name   = 'antragsdaten_2022_antrag'\n     ;\n</code></pre> <p>As we can see in a database the information can be organized in different schemas. Our table 'antragsdaten_2022_antrag' is in the public schema. The query above makes a selection of the columns of this table in that schema. The result shows us a total of 26 columns found in our table 'antragsdaten_2022_antrag'.</p>"},{"location":"blog/posts/statistics_with_SQL/#how-many-records-rows-exist-in-this-table","title":"How many records (rows) exist in this table?","text":"<p>For this we are going to use the COUNT tool in SQL. The following query can be read as: make a count of all the rows in the table.</p> <pre><code>SELECT COUNT(*)\n  FROM antragsdaten_2022_antrag;\n</code></pre> <p> </p> <p>We can see that the table has a total of 286750 records. However, when we make the following query, we can see that some of these records contain incomplete values in some of their columns.</p> <pre><code>SELECT *\nfrom antragsdaten_2022_antrag\nlimit 10;\n</code></pre> <p> </p> <p>We are now going to count all the records that are complete (these are the records that do not have gaps in any of their columns). As we can see in the results, there are some information missing in the columns code_bez, code, which are relevant for later analysis. Let's count how many records have incomplete information in these columns.</p>"},{"location":"blog/posts/statistics_with_SQL/#how-many-records-have-missing-values","title":"How many records have missing values?","text":"<pre><code>SELECT COUNT(*)\nfrom antragsdaten_2022_antrag\nWHERE code IS NULL\nAND\ncode_bez IS NULL;\n</code></pre> <p>What we have told our database is to give us incomplete records by filtering our table by values where the column \"code\" and code_bez have no information (IS NULL).</p>"},{"location":"blog/posts/statistics_with_SQL/#what-is-the-percentage-of-missing-values-and-complete-values-in-relation-of-all-records-in-our-table","title":"What is the percentage of missing values and complete values in relation of all records in our table.","text":"<p>Now we are going to introduce a new concept in PostgresSQL which is the use of UNION. UNION allows us to join two results of select queries into a single table. First let's focus on what is after the comment / UNION OF TWO TABLES / (I have commented it for simplicity and understanding of the query). What we are doing here is first counting the number of rows where the code and code_bez columns have NULL values. After the count we add the value 'missing_values' in a column called category. Then we do the same but with the NON NULL values of the table antragsdaten_2022_antrag. These two queries we \"join\" them using the UNION clause in the middle of them. This result we assign the alias \"t\". Now at the top of the query, we are going to do our calculations. What we do is to select the count column of our newly aliased table \"t\". We also select the category column, and then we do the percentage calculation where we take the value of count, multiply it by one hundred and divide it by the count of all the entries in the table antragsdaten_2022_antrag. This result we assign the alias of percentage.</p> <pre><code>select t.count, t.category, \nt.count*100/(select count(*) from antragsdaten_2022_antrag) percentage\nfrom (\n/* JOINING TWO TABLES */\nSELECT COUNT(*), 'missing_values' category\nfrom antragsdaten_2022_antrag\nWHERE code IS NULL\nAND\ncode_bez IS NULL\n\nUNION \n\nSELECT COUNT(*), 'non_missing_values' category\nfrom antragsdaten_2022_antrag\nWHERE code IS NOT NULL\nAND\ncode_bez IS NOT NULL\n/*##############################*/\n)t\n</code></pre>"},{"location":"blog/posts/statistics_with_SQL/#what-is-the-number-of-parcels-by-code-crop-class","title":"What is the number of parcels by code (crop class)?","text":"<p>To answer this question, we now introduce a concept which is the GROUP BY. This clause allows us to group results according to the values of a column. This clause becomes effective in cases where we calculate a variable for a group. For example: the number of elements (COUNT clause), or the average (AVG clause), or minimum or maximum values (MIN or MAX respectively). In this example we do it for the number of elements per group. First we apply the COUNT clause for all elements, add the value of the code_bez and code column of the table antragsdaten_2022_antrag, for the records with complete data, grouped by the columns code_bez, code and sorted by the result of count in descending order.</p> <pre><code>SELECT COUNT(*), code_bez, code\nfrom antragsdaten_2022_antrag\nWHERE code IS NOT NULL\nAND\ncode_bez IS NOT NULL\nGROUP BY code_bez, code\nORDER BY COUNT DESC\n</code></pre>"},{"location":"blog/posts/statistics_with_SQL/#what-is-the-average-area-of-the-plots","title":"What is the average area of the plots?","text":"<p>For this last query we make use of a PostGIS function ST_Area, which allows us to calculate the area based on the geom column that contains the geometry. We add the value true, after the geom column because it is an area calculated based on a spheroid. The result is returned in square meters, so we divide it by 10 000 to convert this data into hectares. We finish the query by sorting the results by the average values in descending order.</p> <pre><code>SELECT code, code_bez, AVG(ST_Area(geom, true))/10000 avg_area_m2\nfrom antragsdaten_2022_antrag\nWHERE code IS NOT NULL\nAND\ncode_bez IS NOT NULL\nGROUP BY code, code_bez\nORDER BY avg_area_m2 DESC\n</code></pre>"},{"location":"blog/posts/statistics_with_SQL/#conclusion","title":"Conclusion","text":"<p>And that concludes this post on my blog. We have started to ingest data in Shapefile format in a database and start making queries using the SQL language.</p> <p>In a next blog post we will analyze how to make more spatial queries using this table in relation to other tables with other types of information. </p>"},{"location":"portfolio/","title":"Description","text":"<p>My portfolio comprises a collection of functions and algorithms designed to assist geospatial developers in solving common problems encountered in geospatial analysis. This portfolio provides implementations of these solutions in the programming languages, including Python, Julia, and Geoogle Earth Engine Java Script API. The examples can be modified to fit the requirements of your geospatial solutions.</p> <p>Author Roger Almengor Gonz\u00e1lez</p> <p>Contact and website rogeralmengor@gmail.com https://rogeralmengor.github.io/geospatial-analysis.io/</p>"},{"location":"portfolio/Languages/JavaScript%28GEE-API%29/","title":"JavaScript(GEE API)","text":"<p>Welcome to the Google Earth Engine section of this documentation. This section is dedicated to providing a solution-based approach to various geospatial analytics problems, complete with code explanations and illustrative outputs. The code presented here is based on the concepts and functionalities offered by the Google Earth Engine (GEE) JavaScript API.</p> <p>If you are unfamiliar with the GEE JavaScript API or need further information on its usage and capabilities, you can refer to the official Google Earth Engine JavaScript API documentation. This documentation serves as a valuable resource for understanding the core functionalities of the GEE platform and its JavaScript API, which form the foundation for the solutions and projects presented in this section. </p> <p>Feel free to explore the projects and code examples provided here to gain insights into how GEE can be leveraged for various geospatial analysis tasks.</p>"},{"location":"portfolio/Languages/JavaScript%28GEE-API%29/#time-lapse-landsat-images","title":"\ud83c\udfa5 Time Lapse (Landsat Images) \ud83c\udf0d","text":"<p>Time lapse animations, are an interesting tool used to visualize changes on the earth surface over time. The following animation is created by the code provided, and shows the changes over a 20 years period of time by the construction of a river dam in the province of Chiriqui, Republic of Panam\u00e1.</p> <p> Time Lapse of Landsat Images from the Google Earth Engine platform. </p> Code ```javascript title=\"time_lapse.js\" linenums=\"1\"  /*******************************************************************************  * Downloading Image Chips for Hidroelectrica dos Mares  * Location: El Valle de Las Lomas, Chiriqu\u00ed, Panam\u00e1  * Author: Roger Almengor Gonz\u00e1lez  * Data 26.09.2022  * Project: CAP 2022  * Land: Bayern  * ****************************************************************************/   // Feature Collection   var municipalities = ee.List(['Bijagual', 'Chiriqu\u00ed', 'Cochea', 'David',                             'Las Lomas','Gualaca', 'Rinc\u00f3n', 'Paja de Sombrero', 'Caldera', 'Dos R\u00edos', 'Los Anastacios', 'Dolega', 'Pedregal', 'San Pablo Viejo', 'San Pablo Nuevo',                              'San Carlos', 'Hornito', 'Tinajas'])  var AOI = table.filter(ee.Filter.inList('NAME_3', municipalities)); var municipalities = AOI.filter(ee.Filter.eq('NAME_1', 'Chiriqu\u00ed')); var district_list = ee.List(['Gualaca', 'Boquete', 'Dolega', 'David']) var municipalities = municipalities.filter(ee.Filter.inList('NAME_2', district_list)) print(AOI); Map.addLayer(municipalities);  var cochea_district = table.filter(ee.Filter.eq('NAME_3', 'Chiriqu\u00ed')) var centroid_cochea_coor = cochea_district.geometry().centroid()                             .coordinates().getInfo() var x = centroid_cochea_coor[0]; var y = centroid_cochea_coor[1]; print(x);  print(y); Map.setCenter(x, y, 12);   // Elaborating the dates // Getting Temperatures for Every Month var period = ['-01-01', '-12-01'];   var years = [['1999', '2000'], ['2000', '2001'], ['2001', '2002'], ['2002', '2003'], ['2003', '2004'], ['2004', '2005'], ['2005', '2006'], ['2006', '2007'], ['2007', '2008'], ['2008', '2009'],  ['2009', '2010'],  ['2010', '2011'], ['2011', '2012'], ['2012', '2013'], ['2013', '2014'], ];  var add_period = function(year){ var start_date = period[0];  var end_date = period[1]; return [year[0] + start_date, year[1] + end_date]; };  var visualization = { bands: ['SR_B4', 'SR_B3', 'SR_B2'], min: 0.0, max: 0.4, };  var visualization_ = { bands: ['SR_B4_median', 'SR_B3_median', 'SR_B2_median'], min: 0.0, max: 0.4, };  var concatenate_year_with_periods = function(years, period){ return years.map(add_period); };  var Dates = concatenate_year_with_periods(years, period);  print(Dates);  /***********************************************************************    Landsat 5 ************************************************************************/ // Applies scaling factors. function applyScaleFactors(image) { var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2); var thermalBand = image.select('ST_B6').multiply(0.00341802).add(149.0); return image.addBands(opticalBands, null, true) .addBands(thermalBand, null, true); }  var dataset = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2') .filterDate('1999-01-01', '2020-12-31') .filterBounds(municipalities) .map(applyScaleFactors) .map(function(image){return image.clip(municipalities)}); /******************************************************************************* * Downloading Image Chips for Hidroelectrica dos Mares * Location: El Valle de Las Lomas, Chiriqu\u00ed, Panam\u00e1 * Author: Roger Almengor Gonz\u00e1lez * Data 26.09.2022 * Project: CAP 2022 * Land: Panama * *****************************************************************************/  // Feature Collection  //var municipalities = ee.List(['Bijagual', 'Chiriqu\u00ed', 'Cochea', 'David', // 'Las Lomas','Gualaca', 'Rinc\u00f3n', //'Paja de Sombrero', 'Caldera', 'Dos R\u00edos', 'Los Anastacios', 'Dolega',  //'Pedregal', 'San Pablo Viejo', 'San Pablo Nuevo', 'San Carlos', 'Hornito',  // 'Tinajas'])  // Feature Collection  var municipalities = ee.List(['Bijagual','Cochea','Las Lomas']) var AOI = table.filter(ee.Filter.inList('NAME_3', municipalities)); var municipalities = AOI.filter(ee.Filter.eq('NAME_1', 'Chiriqu\u00ed')); var district_list = ee.List(['Gualaca', 'Boquete', 'Dolega', 'David']) var municipalities = municipalities.filter(ee.Filter.inList('NAME_2',                                          district_list)) // Gets the bounds and create geometry var extent = municipalities.geometry().bounds(); var buffered_extent = extent.buffer(ee.Number(10000)                                     .sqrt()                                     .divide(2), 1)                                     .bounds(); //var municipalities = geometry Map.addLayer(municipalities);  var cochea_district = table.filter(ee.Filter.eq('NAME_3', 'Bijagual')) var centroid_cochea_coor = cochea_district.geometry()                                             .centroid()                                             .coordinates()                                             .getInfo()  var x = centroid_cochea_coor[0]; var y = centroid_cochea_coor[1]; Map.setCenter(x, y, 10);   // Elaborating the dates // Getting Temperatures for Every Month var period = ['-01-01', '-12-01'];   var years = [['1999', '2000'], ['2000', '2001'], ['2001', '2002'], ['2002', '2003'], ['2003', '2004'], ['2004', '2005'], ['2005', '2006'], ['2006', '2007'], ['2007', '2008'], ['2008', '2009'],  ['2009', '2010'],  ['2010', '2011'], ['2011', '2012'], ['2012', '2013'], ['2013', '2014'], ];  var add_period = function(year){ var start_date = period[0];  var end_date = period[1]; return [year[0] + start_date, year[1] + end_date]; };  var visualization = { bands: ['SR_B4', 'SR_B3', 'SR_B2'], min: 0.0, max: 0.4, };  var visualization_ = { bands: ['SR_B4_median', 'SR_B3_median', 'SR_B2_median'], min: 0.0, max: 0.4, };  var concatenate_year_with_periods = function(years, period){ return years.map(add_period); };  var Dates = concatenate_year_with_periods(years, period);    /**********************************************************************     Landsat 7  ***********************************************************************/ var visualization = { bands: ['B4', 'B3', 'B2'], min: 0.0, max: 0.3, };  var visualization_ = { bands: ['B4_median', 'B3_median', 'B2_median'], min: 0.0, max: 0.5, gamma: [0.95, 1.1, 1] };  // Applies scaling factors. var cloudMaskL7 = function(image) { var qa = image.select('BQA'); var cloud = qa.bitwiseAnd(1 &lt;&lt; 4) .and(qa.bitwiseAnd(1 &lt;&lt; 6)) .or(qa.bitwiseAnd(1 &lt;&lt; 8)); var mask2 = image.mask().reduce(ee.Reducer.min()); return image //.select(['B3', 'B4'], ['Red', 'NIR']) .updateMask(cloud.not()).updateMask(mask2) .set('system:time_start', image.get('system:time_start')); };  var dataset = ee.ImageCollection('LANDSAT/LE07/C01/T1_TOA') .filterDate('1999-01-01', '2020-12-31') .filterBounds(AOI) //.map(applyScaleFactors) .map(cloudMaskL7) .map(function(image){return image.clip(municipalities)});  //dataset = dataset.map(applyScaleFactors);  // Creating composites using median pixel value var median_yearly_landsat_7 = function(start, end){ var dataset_ =  dataset.filter(ee.Filter.date(start, end)); var median_yearly = dataset_.reduce(ee.Reducer.median()); return median_yearly; };  var composite_name_list_l7 = ee.List([]);  var apply_monthly_composite = function(date_list){ var start = date_list[0]; var end = date_list[1];  var output_name = start + \"TO\" + end + \"_LANSAT_7\"; var composite = median_yearly_landsat_7(start, end); composite_name_list_l7 = composite_name_list_l7.add([composite, output_name]); Map.addLayer(composite, visualization_, output_name, false); Export.image.toDrive({ image: composite, description: output_name, fileFormat: 'GeoTIFF', crs : 'EPSG:4326', folder : 'LANDSAT_LST_LAS_LOMAS', region: municipalities }); return 0;  };  Dates.map(apply_monthly_composite);    /****************************************************************** // Animation gif  // Create RGB visualization images for use as animation frames. /******************************************************************/ var text = require('users/gena/packages:text'); var annotated_collection_list = ee.List([]) var annotations = [ {position: 'left',  offset: '0.25%',  margin: '0.25%',  property: 'label',  scale: 250} //large scale because image if of the whole world. Use smaller scale ];  var create_annotated_collection = function(image_and_id) { var img = image_and_id[0]; var image_id = image_and_id[1]; print(image_id); var img_out = img.visualize(visualization_) //.clip(geometry)//.paint(municipalities, 'FF0000', 2) .set({'label': image_id}); Map.addLayer(img_out); var annotated = text.annotateImage(img_out, {}, Bayern, annotations); annotated_collection.add(annotated); return 0; };  var municipalities_geom = geometry; var n = composite_name_list_l7.size().getInfo(); print(n); for (var i = 0; i &lt; n; i++) { var img_info = ee.List(composite_name_list_l7.get(i)); print(img_info); var img = ee.Image(img_info.get(0)); var img_id = ee.String(img_info.get(1)); var year = ee.String(ee.List(img_id.split(\"-\").get(0))); var month = ee.String(ee.List(img_id.split(\"-\").get(1))); var img_id_ = year.getInfo() // + \"_\" + month.getInfo(); var img_out = img.visualize(visualization_) //.paint(geometry, 'FF0000', 2) .set({'label': img_id_}); var annotated = text.annotateImage(img_out, {}, buffered_extent, annotations); Map.addLayer(annotated); var annotated_collection_list = annotated_collection_list.add(annotated) }  var annotated_col = ee.ImageCollection(annotated_collection_list)  // Define GIF visualization parameters. var gifParams = { 'region': buffered_extent, 'dimensions': 508, //'crs': 'EPSG:32632', 'framesPerSecond': 1 };  // Print the GIF URL to the console. print(annotated_col.getVideoThumbURL(gifParams)); // Render the GIF animation in the console. print(ui.Thumbnail(annotated_col, gifParams));  <pre><code>&lt;/details&gt;\n\n##\ud83c\udf10 **Measuring land surface temperature with MODIS data** \ud83c\udf21\ufe0f\ud83d\udef0\ufe0f\n\n**Script Description:**\nThis script is designed to analyze temperature changes within the Cochea River watershed using the Google Earth Engine (GEE) platform and MODIS (Moderate Resolution Imaging Spectroradiometer) datasets. Specifically, it focuses on measuring temperature variations during both the rainy and dry seasons over a 20-year period. The primary objectives of this script are to generate an animated GIF, a time series graph depicting the Average Median Temperature (\u00b0C) as recorded by the MODIS sensor, and a regional overview of the study area.\n\n**Script Workflow:**\n1. **Data Acquisition:** The script begins by accessing MODIS datasets, which provide reliable temperature data with global coverage and high temporal resolution.\n\n2. **Temporal Selection:** It then filters the MODIS data to isolate the specific time periods corresponding to the dry and wet seasons over the 20-year span.\n\n3. **Spatial Region Selection:** The script defines the study area within the Cochea River watershed, ensuring that the analysis is limited to the relevant geographic scope.\n\n4. **Temperature Computation:** Using the MODIS temperature data, the script calculates the Average Median Temperature (\u00b0C) for each pixel within the study area, both for the dry and wet seasons.\n\n5. **Visualization Generation:**\n   - *Animated GIF:* The script generates an animated GIF, showcasing the temporal evolution of temperature changes over the 20-year period. Each frame of the GIF represents a specific time step, offering a dynamic visual representation of temperature variations.\n    &lt;p align=\"center\"&gt;\n      &lt;img src=\"./../dry_season_20_years_modis.gif\" alt=\"Centered Image\"&gt;\n      &lt;br&gt;\n    &lt;i&gt;Time Lapse of MODIS Land Surface Temperature (Dry Season) from the Google Earth Engine platform.&lt;/i&gt;\n    &lt;/p&gt;\n    &lt;br&gt;\n    &lt;p align=\"center\"&gt;\n      &lt;img src=\"./../rainy_season_20_years_modis.gif\" alt=\"Centered Image\"&gt;\n      &lt;br&gt;\n    &lt;i&gt;Time Lapse of MODIS Land Surface Temperature (Rainy Season) from the Google Earth Engine platform.&lt;/i&gt;\n    &lt;/p&gt;\n    &lt;br&gt;\n\n   - *Time Series Graph:* Additionally, the script creates a time series graph, displaying the Average Median Temperature (\u00b0C) as a function of time. This graph provides a clear overview of temperature trends during the dry and wet seasons.\n    &lt;p align=\"center\"&gt;\n      &lt;img src=\"./../Average_Median_Temp_Dry_Season-1024x422.png\" alt=\"Centered Image\"&gt;\n      &lt;br&gt;\n      &lt;i&gt;Average median temperature for the Dry Season measured from MODIS time series.&lt;/i&gt;\n      &lt;/p&gt;\n    &lt;br&gt;\n\n    &lt;p align=\"center\"&gt;\n      &lt;img src=\"./../Average_Median_Temp_Rainy_Season-768x316.png\" alt=\"Centered Image\"&gt;\n      &lt;br&gt;\n      &lt;i&gt;Average median temperature for the Wet Season measured from MODIS time series.&lt;/i&gt;\n      &lt;/p&gt;\n    &lt;br&gt;\n\n   - *Regional View:* Lastly, the script produces a regional view of the study area, allowing users to geospatially contextualize the temperature changes observed in the Cochea River watershed.\n\n    &lt;p align=\"center\"&gt;\n      &lt;img src=\"./../Regional_and_country_wide_location.jpg\" alt=\"Centered Image\"&gt;\n      &lt;br&gt;\n      &lt;i&gt;Regional view of the study area.&lt;/i&gt;\n      &lt;/p&gt;\n    &lt;br&gt;\n\nBy following this technical script, users can conduct a rigorous analysis of temperature fluctuations within the specified region and timeframes, enabling in-depth insights into environmental changes over the 20-year period.\n\n&lt;details&gt;\n  &lt;summary&gt;Code&lt;/summary&gt;\n```javascript title=\"land_surface_MODIS.js\" linenums=\"1\"\n// Feature Collection \nvar districts = ee.List(['Bijagual','Cochea','Las Lomas'])\nvar AOI = table.filter(ee.Filter.inList('NAME_3', districts));\nvar districts = AOI.filter(ee.Filter.eq('NAME_1', 'Chiriqu\u00ed'));\nMap.addLayer(districts.union())\n\n// Setting the Map to the coordinates of one of our districts\nvar cochea_district = table.filter(ee.Filter.eq('NAME_3', 'Bijagual'));\nvar centroid_cochea_coor = cochea_district.geometry().centroid().coordinates().getInfo();\nvar x = centroid_cochea_coor[0];\nvar y = centroid_cochea_coor[1];\nMap.setCenter(x, y, 10);\n\n// Raster Visualization Parameters\nvar landSurfaceTemperatureVis = {\n  min: 0, max: 40,\n  palette: ['blue', 'limegreen', 'yellow', 'darkorange', 'red']};\n\n  // Image Collection MODIS Surface Temperature Median Values \n// (Dry Season January - March)\n// (Wet Season April - December)\nvar startYear = 2001;\nvar endYear = 2020;\nvar DrySeasonMedianCollection = ee.ImageCollection(\n  ee.List.sequence(startYear, endYear)\n    .map(createDrySeasonMedianComposite)\n);\n\nvar WetSeasonMedianCollection = ee.ImageCollection( \n  ee.List.sequence(startYear, endYear)\n  .map(createWetSeasonMedianComposite)\n);\n\nfunction createDrySeasonMedianComposite(year) {\nvar startDate = ee.Date.fromYMD(year, 1, 1);\nvar endDate = ee.Date.fromYMD(year, 3, 31);\nvar description = startDate.format('yyyy-MM-dd')\n.cat(' TO ')\n.cat(endDate.format('yyyy-MM-dd'));\nreturn ee.ImageCollection('MODIS/061/MOD11A1')\n.filterBounds(districts)\n.filterDate(startDate, endDate)\n.select('LST_Day_1km')\n.map(function(img) {\nreturn img\n.multiply(0.02)\n.subtract(273.15)\n.copyProperties(img, ['system:time_start']);\n})\n.median()\n.set('year', year)\n.set('description', description);\n}\n\nfunction createWetSeasonMedianComposite(year) {\nvar startDate = ee.Date.fromYMD(year, 4, 1);\nvar endDate = ee.Date.fromYMD(year, 12, 31);\nvar description = startDate.format('yyyy-MM-dd')\n.cat(' TO ')\n.cat(endDate.format('yyyy-MM-dd'));\nreturn ee.ImageCollection('MODIS/061/MOD11A1')\n.filterBounds(districts)\n.filterDate(startDate, endDate)\n.select('LST_Day_1km')\n.map(function(img) {\nreturn img\n.multiply(0.02)\n.subtract(273.15)\n.copyProperties(img, ['system:time_start']);\n})\n.median()\n.set('year', year)\n.set('description', description);\n}\n\nDrySeasonMedianMultiBandImg = DrySeasonMedianCollection\n      .toBands()\n      .select('[0-9]{1,2}_LST_Day_1km');\n\nWetSeasonMedianMultiBandImg = WetSeasonMedianCollection\n      .toBands()\n      .select('[0-9]{1,2}_LST_Day_1km');\n\n// Define a dictionary that associates band names with values \nvar TempInfo = {\n  '0_LST_Day_1km': {v: 1, f: '2001'},\n  '1_LST_Day_1km': {v: 2, f: '2002'},\n  '2_LST_Day_1km': {v: 3, f: '2003'},\n  '3_LST_Day_1km': {v: 4, f: '2004'},\n  '4_LST_Day_1km': {v: 5, f: '2005'},\n  '5_LST_Day_1km': {v: 6, f: '2006'},\n  '6_LST_Day_1km': {v: 7, f: '2007'},\n  '7_LST_Day_1km': {v: 8, f: '2008'},\n  '8_LST_Day_1km': {v: 9, f: '2009'},\n  '9_LST_Day_1km': {v: 10, f: '2010'},\n  '10_LST_Day_1km': {v: 11, f: '2011'},\n  '11_LST_Day_1km': {v: 12, f: '2012'},\n  '12_LST_Day_1km': {v: 13, f: '2013'},\n  '13_LST_Day_1km': {v: 14, f: '2014'},\n  '14_LST_Day_1km': {v: 15, f: '2015'},\n  '15_LST_Day_1km': {v: 16, f: '2016'},\n  '16_LST_Day_1km': {v: 17, f: '2017'},\n  '17_LST_Day_1km': {v: 18, f: '2018'},\n  '18_LST_Day_1km': {v: 19, f: '2019'},\n  '19_LST_Day_1km': {v: 20, f: '2020'},\n}\n\nvar xPropVals = [];\nvar xPropLabels = [];\n\nfor (var key in TempInfo){\n  xPropVals.push(TempInfo[key].v);\n  xPropLabels.push(TempInfo[key]);\n}\n\n// Apply the dissolve method to the Geometry object.\nprint(districts)\nvar geometryDissolve = districts.union();\n\n// Define the chart and print it to the console.\nvar chartDrySeason = ui.Chart.image\n                .regions({\n                  image: DrySeasonMedianMultiBandImg,\n                  regions: districts.union(),\n                  reducer: ee.Reducer.mean(),\n                  scale: 500,\n                  seriesProperty: 'label',\n                  xLabels: xPropVals\n                })\n                .setChartType('LineChart')\n                .setOptions({\n                  title: 'Average (Median) Temperature (\u00b0C) Dry Season (Jan-Mar)',\n                  hAxis: {\n                    title: 'Year',\n                    titleTextStyle: {italic: false, bold: true},\n                    ticks: xPropLabels\n                  },\n                  vAxis: {\n                    title: 'Temperature (\u00b0C)',\n                    titleTextStyle: {italic: false, bold: true}\n                  },\n                  colors: ['f0af07', '0f8755', '76b349'],\n                  lineSize: 3\n});\nprint(chartDrySeason);\n\n// Define the chart and print it to the console.\nvar chartWetSeason = ui.Chart.image\n                .regions({\n                  image: WetSeasonMedianMultiBandImg ,\n                  regions: districts.union(),\n                  reducer: ee.Reducer.mean(),\n                  scale: 500,\n                  seriesProperty: 'label',\n                  xLabels: xPropVals\n                })\n                .setChartType('LineChart')\n                .setOptions({\n                  title: 'Average (Median) Temperature (\u00b0C) Rainy Season (Apr-Dec)',\n                  hAxis: {\n                    title: 'Year',\n                    titleTextStyle: {italic: false, bold: true},\n                    ticks: xPropLabels\n                  },\n                  vAxis: {\n                    title: 'Temperature (\u00b0C)',\n                    titleTextStyle: {italic: false, bold: true}\n                  },\n                  colors: ['0f8755', '76b349'],\n                  lineSize: 3\n});\nprint(chartWetSeason);\n\n// Define GIF visualization parameters.\nvar gifParams = {\n  'region': buffered_extent,\n  'dimensions': 600,\n  'framesPerSecond': 1.5\n};\n\nvar text = require('users/gena/packages:text'); // Import gena's package which allows text overlay on image\n\nvar annotations = [\n {position: 'left', offset: '0.25%', margin: '0.25%', property: 'label', scale: 100} //large scale because image if of the whole world. Use smaller scale otherwise\n  ];\n\nfunction addText(image){\n  var image_0 = image.clip(districts.union());\n  var timeStamp = image.get('description'); // get the time stamp of each frame. This can be any string. Date, Years, Hours, etc.\n  var timeStamp_ = ee.String(timeStamp); //convert time stamp to string \n  var image_ = image_0.visualize(landSurfaceTemperatureVis).set({'label':timeStamp}); // set a property called label for each image\n  var annotated = text.annotateImage(image_, {}, extent, annotations); // create a new image with the label overlayed using gena's package\n  return annotated;\n}\n\nvar AnnotatedCollectionWetSeason = WetSeasonMedianCollection.map(addText); //add time stamp to all images\nvar AnnotatedCollectionDrySeason = DrySeasonMedianCollection.map(addText);\n\n\nprint(ui.Thumbnail(AnnotatedCollectionWetSeason,  gifParams));\n\nvar AnnotatedCollectionDrySeason = DrySeasonMedianCollection.map(addText);\n\nprint(ui.Thumbnail(AnnotatedCollectionDrySeason,  gifParams));\n\n// ui.Map objects can be constructed. Here, a new map is declared.\nvar newMap = ui.Map({\n  center: {lat: 8, lon: -80, zoom: 5.5\n  },\n  style: {position: 'bottom-right', width: '400px'}\n});\n\nvar geomLayer = ui.Map.Layer(districts.union(), {color: 'red'}, 'Area of Interest');\nvar extentLayer = ui.Map.Layer(districts.bounds, {color:'red'}, 'Extent');\nnewMap.add(geomLayer);\nnewMap.add(extentLayer);\n\n// Add the newMap to the defaultMap;\nMap.add(newMap);\n\n// Other UI widgets can be added to ui.Map objects, for example labels:\ndefaultMap.add(ui.Label('Countrywide location', {position: 'bottom-left'}));\nnewMap.add(ui.Label('Regional Location', {position: 'bottom-left'}));\n\nMap.setControlVisibility({all: false});\nnewMap.setControlVisibility({all: false});\nMap.setOptions(\"SATELLITE\");\n\n</code></pre>"},{"location":"portfolio/Languages/JavaScript%28GEE-API%29/#time-lapse-radar-images-panama-canal","title":"\ud83c\udf0d Time Lapse (RADAR Images) - Panama Canal \ud83d\udef6 \ud83d\udca7","text":"<p>Objective</p> <p>To commemorate World Water Day, this analysis explores the significance of freshwater sources within the Panama Canal Zone. Our primary goal is to gain insights into the role of these water bodies in sustaining the Panama Canal and supporting the surrounding ecosystems and communities.     <p> Time Series of Radar (Sentinel-1) Imagery. Year 2022, Panama Canal Zone. </p> </p> <p>Methodology</p> <p>In this analysis, we utilize Sentinel-1 imagery due to its exceptional ability to provide clear, all-weather views of the Earth's surface. Our methodology can be broken down into the following key steps:</p> <ol> <li> <p>Filtering Area of Interest (AOI): We narrow our focus to specific regions, including the Panama Province and select districts.</p> </li> <li> <p>Date Range Selection: Images from 2022 are chosen for analysis.</p> </li> <li> <p>Image Clipping and Masking: We create buffered extents and apply masks to Sentinel-1 images.</p> </li> <li> <p>Image Collection and Filtering: We gather images with precise properties, including polarization, resolution, and instrument mode.</p> </li> <li> <p>Backscatter Analysis: Backscatter graphs for VH and VV bands are generated to monitor changes over time.</p> </li> <li> <p>Image Visualization: We visualize images and create RGB representations for animations.</p> </li> </ol> Code ``` javascript title=\"sentinel_1_time_lapse.js\" linenums=\"1\" // Filtering Feature Collection to Area of Interest (AOI) var GAUL_country_boundaries = ee.FeatureCollection(\"FAO/GAUL/2015/level2\");  var provinces = ee.List(['Panam\u00e1', 'Col\u00f3n']) var Panama =  GAUL_country_boundaries.filter(ee.Filter.inList('ADM1_NAME', provinces)); print(Panama)  Map.addLayer(Panama, {color: 'green'}, 'Panama Province'); var districts = ee.List(['Arraij\u00e1n', 'Panam\u00e1', 'San Miguelito', 'Col\u00f3n','Chagres']); var Panama = Panama.filter(ee.Filter.inList('ADM2_NAME', districts));  Map.addLayer(Panama);   //Parameter: Start and End date for images to be queried var start = '2022-01-01'; var end = '2022-12-31'; var dateRange = ee.DateRange(start, end);   // Gets the bounds and create geometry (rectangle around the polygon) var extent = Panama.geometry().bounds();  //Map.addLayer(extent); // Adds this geometry to the map  // Creating a buffered version of the extent var buffered_extent = extent.buffer(ee.Number(50000).sqrt().divide(2), 1).bounds();  Map.addLayer(buffered_extent); // Adds this geometry to the map  // Centering the map to our target parcel Map.centerObject(Panama, 15);  // Function to clip image  function clip_image(image){   return image.clip(buffered_extent);  }  // Function to mask image to certain backscatter signal function update_s1_mask(image) {           var edge = image.lt(-30.0);           var maskedImage = image.mask().and(edge.not());           return image.updateMask(maskedImage);         }    // Getting an image collection of Sentinel-1 GRDH and VV-VH bands var s1_collection = ee.ImageCollection('COPERNICUS/S1_GRD')                     .filterDate(dateRange)                     .filterBounds(buffered_extent)                     .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))                     .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))                     .filter(ee.Filter.eq('resolution_meters', 10))                     .filter(ee.Filter.eq('instrumentMode', 'IW'))                     .map(update_s1_mask);  var s1_collection_ = s1_collection.select(['VV', 'VH']);  // Dividing the collection according to Orbits (Ascending or Descending) var desc = s1_collection_.filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING')); var asc = s1_collection_.filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING'));  // Checking out how many images are in every batch (ascending, descending) print('descending tiles ', desc.size()); print('ascending tiles ', asc.size());   // Create backscatter (dB) graph for VH and VV bands of Sentinel-1 var chart =     ui.Chart.image         .series({           imageCollection: desc,           region: Panama,           reducer: ee.Reducer.median(),           scale: 500,           xProperty: 'system:time_start'         })         .setSeriesNames([])         .setOptions({           title: 'Median dB for parcel: ' + \"Panama_Canal_Zone\",           hAxis: {title: 'Date', titleTextStyle: {italic: false, bold: true}},           vAxis: {             title: 'Backscatter (dB)',             titleTextStyle: {italic: false, bold: true}           },           lineWidth: 5,           colors: ['#00FF7F', '#3CB371'],           curveType: 'function'         }); print(chart);  // Paint the edges with different colors and widths. var empty = ee.Image().byte();  var outlines = empty.paint({   featureCollection: Panama,   width: 'NNH' });  var palette = ['#FFFF00'];  // Adding every image of the image collection on the Map var s1_vis_params = {bands: [\"VV\",\"VH\",\"VV\"],                         min: -25,                          max: 5,                          gamma:1,                          opacity:1};  function addImage(image) {    var id = image.id;   var image_ = ee.Image(image.id);   Map.addLayer(image_, s1_vis_params,                          id)}   asc.evaluate(function(asc) {  // use map on client-side   asc.features.map(addImage);   Map.addLayer(outlines, {palette: palette, max: 14}, 'Panama'); });  // Create RGB visualization images for use as animation frames. var rgbVis = asc.map(function(img) {   return img.visualize(s1_vis_params).clip(buffered_extent); });  //Create an animated GIF // Define GIF visualization parameters. var gifParams = {   'region': buffered_extent,   'dimensions': 1100,   'crs': 'EPSG:4326',   'framesPerSecond': 5 };  // Print the GIF URL to the console. print(rgbVis.getVideoThumbURL(gifParams));  // Render the GIF animation in the console. print(ui.Thumbnail(rgbVis, gifParams));  <pre><code>&lt;/details&gt;\n\n##\ud83d\udca8 **Monitoring Nitrogen Dioxide in Panama City with Sentinel-5P Imagery** \ud83c\udfd9\ufe0f\n\n**Objective:**\n\nThe objective of this analysis is to create composites of Sentinel-5P imagery to measure nitrogen dioxide (NO2) levels in the city of Panama City during the COVID-19 lockdown period. This analysis aims to provide insights into the variations in tropospheric NO2 density over time, particularly during the lockdown period, and visualize these changes using composites and a time-lapse GIF. The analysis also includes the creation of a chart to represent the mean NO2 levels over the selected area of interest.\n\n**Steps:**\n\n1. **Filtering Area of Interest (AOI):** The analysis starts by defining the Area of Interest (AOI) using geographical boundaries data. The AOI encompasses specific districts within the Panama Province, including Arraij\u00e1n, Panam\u00e1, and San Miguelito. The map is centered on the coordinates of this AOI.\n\n2. **Setting Visualization Parameters:** Visualization parameters for the NO2 density are defined, including the minimum, maximum values, and color palette to be used for rendering the imagery.\n\n3. **Setting the Date Range:** The analysis specifies the start and end dates for image collection. In this case, the date range spans from January 1, 2020, to December 31, 2022.\n\n4. **Creating Image Composites:** The script creates monthly image composites of Sentinel-5P tropospheric NO2 density within the defined AOI. These composites are generated for each month of each year in the specified date range.\n\n5. **Renaming Images:** The image composites are renamed to include the year and month information in their system index.\n\n6. **Creating a Time-Lapse GIF:** The script combines the renamed image composites into a time-lapse GIF. It annotates each frame of the GIF with a timestamp to indicate the year and month of the data. The GIF visually shows the changes in tropospheric NO2 density over time within the AOI.\n\n7. **Creating a Chart:** A chart is generated to display the mean tropospheric NO2 column number density for the selected AOI over time. This chart provides a quantitative representation of the NO2 levels during the analysis period.\n    &lt;p align=\"center\"&gt;\n      &lt;img src=\"./../NOx_Panama_City_2019-2022-1024x540.png\" alt=\"Centered Image\"&gt;\n      &lt;br&gt;\n      &lt;i&gt;Tropospheric NO2 column \u2013 Chart&lt;/i&gt;\n      &lt;/p&gt;\n    &lt;br&gt;\n\n8. **Displaying Yearly Composites:** Finally, yearly composites for 2019, 2020, 2021, and 2022 are added to the map, allowing for a comparison of NO2 levels across these years.\n    &lt;p align=\"center\"&gt;\n      &lt;img src=\"./../nitrogen_dioxide_2019_2022.jpg\" alt=\"Centered Image\"&gt;\n      &lt;br&gt;\n      &lt;i&gt;Nitrogen Dioxide tropospheric column \u2013 Panama City \u2013 2019-2022\n&lt;/i&gt;\n      &lt;/p&gt;\n    &lt;br&gt;\nThis analysis provides a comprehensive overview of tropospheric NO2 density changes in Panama City, with a focus on the COVID-19 lockdown period. The time-lapse GIF and chart enhance the visualization and understanding of these changes over time.\n\n&lt;details&gt;\n  &lt;summary&gt;Code&lt;/summary&gt;\n```javascript title=\"nitrogen_dioxide_monitoring.js\" linenums=\"1\"\n// Filtering Feature Collection to Area of Interest (AOI)\nvar GAUL_country_boundaries = ee.FeatureCollection(\"FAO/GAUL/2015/level2\");\n\nvar Panama = GAUL_country_boundaries.filter(ee.Filter.eq('ADM1_NAME', 'Panam\u00e1'));\nprint(Panama);\nMap.addLayer(Panama, {color: 'green'}, 'Panama Province');\nvar districts = ee.List(['Arraij\u00e1n', 'Panam\u00e1', 'San Miguelito']);\nvar AOI = Panama.filter(ee.Filter.inList('ADM2_NAME', districts));\nvar AOI_ = AOI.union();\nMap.addLayer(AOI_, {color: 'blue'}, 'Area of Interest');\n\n// Setting the Map to the coordinates of one of our districts\nvar centroid_coor =  AOI_.geometry().centroid().coordinates().getInfo();\nvar x = centroid_coor[0];\nvar y = centroid_coor[1];\nMap.setCenter(x, y, 10);\n\n// Setting visualization parameters\nvar band_viz = {\n  min: 0,\n  max: 0.0002,\n   palette: ['white', 'orange', 'red', 'cyan', 'purple', 'green']\n};\n\n// Setting the start and end date\n// and creating the list of month and dates\nvar date_start = ee.Date('2020-01-01');\nvar date_end= ee.Date('2022-12-31');\n\nvar months = ee.List.sequence(1, 12);//separate by years\nvar years = ee.List.sequence(date_start.advance(-1,\"year\")\n                                       .get(\"year\"),\n                             date_end.get(\"year\"));\n\n// Creating the image composites (monthly time series)\n// of Sentinel-5P tropospheric NO2 density\nvar year_composite = years.map(function(y){\n  return months.map(function(m){\n    return ee.ImageCollection('COPERNICUS/S5P/OFFL/L3_NO2')\n            .select('tropospheric_NO2_column_number_density')\n            .filter(ee.Filter.calendarRange(y, y,'year'))\n            .filter(ee.Filter.calendarRange(m, m,'month'))\n            .median()\n            .set('year',y)\n            .set('month', m)\n            .clip(AOI_);\n})});\n\nfunction decomposeList(l) {\n  return ee.ImageCollection.fromImages(l).toList(12);\n}\n\nvar list_imgs = year_composite.map(decomposeList).flatten();\n\n// Setting as index the year and month \n// of the layer being created\nfunction renameImages(img){\n  var img_1 = ee.Image(img);\n  var value = ee.Number(img_1.get('year')).format('%04d')\n              .cat('_').cat(ee.Number(img_1.get('month')).format('%02d'));\n  var img_2 = img_1.set('system:index', value, 'system:id', value);\n  return img_2;\n}\n\nvar list_imgs_renamed = list_imgs.map(renameImages);\n\nvar img_collection = ee.ImageCollection.fromImages(list_imgs_renamed);\n\n// Create time lapse \nvar text = require('users/gena/packages:text'); // Import gena's package which allows text overlay on image\n\nvar annotations = [\n {position: 'left', offset: '0.25%', margin: '0.25%', property: 'label', scale: 1000} //large scale because image if of the whole world. Use smaller scale otherwise\n  ];\n\nfunction addText(image){\n  var timeStamp = image.id();\n  var image_ = image.visualize(band_viz).set({'label':timeStamp}); // set a property called label for each image\n  var annotated = text.annotateImage(image_, {}, AOI_.geometry(), annotations); // create a new image with the label overlayed using gena's package\n  return annotated;\n}\n\nvar extent = AOI_.geometry().bounds();\n\nvar buffered_extent = extent.buffer(ee.Number(10000).sqrt().divide(2), 1).bounds();\n\n// Define GIF visualization parameters.\nvar gifParams = {\n  'region': buffered_extent,\n  'dimensions': 600,\n  //'crs': 'EPSG:3857',\n  'framesPerSecond': 1.5\n};\n\nvar annotated_collection = img_collection.map(addText);\n\n\n// Print the GIF URL to the console.\nprint(ui.Thumbnail(annotated_collection, gifParams));\nui.Thumbnail(annotated_collection, gifParams);\n\n// Define the chart and print it to the console.\nvar chart =\n    ui.Chart.image\n        .seriesByRegion({\n          imageCollection: img_collection,\n          band: 'tropospheric_NO2_column_number_density',\n          regions: AOI_,\n          reducer: ee.Reducer.mean(),\n          scale: 500,\n          seriesProperty: 'label',\n          xProperty: 'system:id'\n        })\n        .setOptions({\n          title: 'tropospheric NO2 column number density Years 2019-2022',\n          hAxis: {title: 'Date', titleTextStyle: {italic: false, bold: true},\n                   format: 'short'\n          },\n          vAxis: {\n            title: 'NOx \u00b5mol/m2',\n            titleTextStyle: {italic: false, bold: true},\n          },\n          lineWidth: 3,\n        });\n\n//print(chart);\n\nprint(img_collection);\n\n// Adding yearly composites\n\nvar imgs_2019 = img_collection.filter(ee.Filter.eq('year', 2019));\n\nMap.addLayer(imgs_2019.mean(), band_viz, 'S5P N02_2019');\n\nvar imgs_2020 = img_collection.filter(ee.Filter.eq('year', 2020));\n\nMap.addLayer(imgs_2020.mean(), band_viz, 'S5P N02_2020');\n\nvar imgs_2021 = img_collection.filter(ee.Filter.eq('year', 2021));\n\nMap.addLayer(imgs_2021.mean(), band_viz, 'S5P N02_2021');\n\nvar imgs_2022 = img_collection.filter(ee.Filter.eq('year', 2022));\n\nMap.addLayer(imgs_2022.mean(), band_viz, 'S5P N02_2022');\n</code></pre>"},{"location":"portfolio/Languages/JavaScript%28GEE-API%29/#frog-monkey-tiger-parrot-google-earth-engine-app-minera-panama-truck-gem","title":":frog: :monkey: :tiger: :parrot: Google Earth Engine App - Minera Panama :truck: :gem:","text":"<p>This project utilizes Earth Engine, a cloud-based platform for geospatial analysis, to process Landsat 7 satellite imagery to create True Color COmposites in the region of Petaquilla, Republic of Panama. The script focuses on an area within Donoso District, which is part of the Mesoamerican Biological Corridor.</p> <p>This workflow automates the creation, visualization, and export of median composites of Landsat 7 images for monitoring the Petaquilla Minera Panama area over time, including the creation of an annotated GIF animation.</p> <p>Description of Functions and Steps</p> <p>Functions</p> <p>applyScaleFactors(image):</p> <p>Adjusts optical and thermal bands of an image using specific scaling factors for accurate representation.</p> <p>maskL7srClouds(image):</p> <p>Masks out clouds and cloud shadows in Landsat 7 images by using bitwise operations on QA_PIXEL data.</p> <p>blendImage(image):</p> <p>Applies a focal mean filter to smooth the image and blends it with the original image to reduce noise.</p> <p>median_yearly_landsat_7(start, end):</p> <p>Creates a median composite of Landsat 7 images for a specified date range, filtered by the AOI and cloud cover threshold.</p> <p>Steps for the Application</p> <ul> <li> <p>Define Area of Interest (AOI):</p> </li> <li> <p>Set the AOI to the geometry variable.</p> </li> <li> <p>Create a buffered extent around the AOI for analysis.</p> </li> <li> <p>Set Cloud Cover Threshold: Define the maximum acceptable cloud cover for images (set to 100%).</p> </li> <li> <p>Prepare Date Ranges: Define periods for data collection and segment years into intervals. Concatenate years with periods to generate specific date ranges.</p> </li> <li> <p>Generate Composites: For each date range, create median composites of Landsat 7 images using the median_yearly_landsat_7 function. Apply cloud masking and image blending to enhance the quality of the composites. Clip the composites to the AOI and add them to the map.</p> </li> <li> <p>Export Composites: Export the generated composites to Google Drive as GeoTIFF files with descriptive names.</p> </li> <li> <p>Annotate Images: Use the text package to annotate the composites with labels.</p> </li> <li> <p>Create a collection of annotated images.</p> </li> <li> <p>Create GIF Animation:</p> </li> </ul> <p>Define GIF parameters, including region, dimensions, and frame rate. Generate and display a GIF animation of the annotated image collection.</p> Code ```javascript title=\"petaquilla_mosaics.js\" linenums=\"1\" /*******************************************************************************  * Petaquilla Minera Panama 2015 - present  * Location: Donoso District, Colon, Republic of Panama  * Author: Roger Almengor Gonz\u00e1lez  * Date 26.11.2023  * ****************************************************************************/  //var districts_list = ee.List(['Donoso']); //var districts = table.filter(ee.Filter.inList('NAME_2', districts_list)); //var extent = districts.geometry().bounds(); //var AOI = extent.buffer(ee.Number(10000).sqrt().divide(2), 1).bounds();  var AOI = geometry;  var CLOUD_COVER = 100  var buffered_extent = AOI.buffer(ee.Number(10000)                                     .sqrt()                                     .divide(2), 1)                                     .bounds();   // Elaborating the dates // Getting Temperatures for Every Month var period = ['-01-01', '-12-01'];   var years = [ ['2005', '2010'], ['2011', '2015'], ['2016', '2020'], ['2021', '2023'], ];  var add_period = function(year){ var start_date = period[0];  var end_date = period[1]; return [year[0] + start_date, year[1] + end_date]; };  var visualization = {   min: 8000,   max: 19000,   gamma: 1.5,   bands: ['SR_B7_median', 'SR_B5_median', 'SR_B3_median'], };   var concatenate_year_with_periods = function(years, period){ return years.map(add_period); };  var Dates = concatenate_year_with_periods(years, period);  print(Dates);   // Applies scaling factors. function applyScaleFactors(image) {   var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);   var thermalBand = image.select('ST_B6').multiply(0.00341802).add(149.0);   return image.addBands(opticalBands, null, true)               .addBands(thermalBand, null, true); }  function maskL7srClouds(image) {   var qa = image.select('QA_PIXEL');   // If the cloud bit (5) is set and the cloud confidence (7) is high   // or the cloud shadow bit is set (3), then it's a bad pixel.   var cloud = qa.bitwiseAnd(1 &lt;&lt; 5)                   .and(qa.bitwiseAnd(1 &lt;&lt; 7))                   .or(qa.bitwiseAnd(1 &lt;&lt; 3));   // Remove edge pixels that don't occur in all bands   var maskL7 = image.mask().reduce(ee.Reducer.min());   return image.updateMask(cloud.not()).updateMask(maskL7); }  function blendImage(image) {   // Apply a focal mean filter to the image   var focalMeanImage = image.focalMean(1, \"square\", \"pixels\", 1);    // Blend the filtered image with the original image   var blendedImage = focalMeanImage.blend(image);    return blendedImage; }  // Creating composites using median pixel value var median_yearly_landsat_7 = function(start, end){ print(\"filtering per dates\"); print(start); print(end); var dataset_ =  ee.ImageCollection(\"LANDSAT/LE07/C02/T1_L2\")                  .filterDate(start, end)                   .filterBounds(AOI)                   .filterMetadata('CLOUD_COVER', 'less_than', CLOUD_COVER)                   //.map(applyScaleFactors)                   .map(maskL7srClouds)                   .map(blendImage)                   .map(function(image){return image.clip(AOI)}); print(\"DATASET_:\") print(dataset_); var median_yearly = dataset_.reduce(ee.Reducer.median()); return median_yearly; };  var composite_name_list_l7 = ee.List([]);   var apply_monthly_composite = function(date_list){ var start = date_list[0]; var end = date_list[1];  var output_name = start + \"TO\" + end + \"_SENTINEL-2\"; var composite = median_yearly_landsat_7(start, end); print(composite); composite_name_list_l7 = composite_name_list_l7.add([composite, output_name]); Map.addLayer(composite, visualization, output_name, false); Export.image.toDrive({ image: composite, description: output_name, fileFormat: 'GeoTIFF', crs : 'EPSG:4326', folder : 'LANDSAT_LST_LAS_LOMAS', region: AOI }); return 0;  };  Dates.map(apply_monthly_composite);    /****************************************************************** // Animation gif  // Create RGB visualization images for use as animation frames. /******************************************************************/ var text = require('users/gena/packages:text'); var annotated_collection_list = ee.List([]) var annotations = [ {position: 'left',  offset: '0.25%',  margin: '0.25%',  property: 'label',  scale: 250} //large scale because image if of the whole world. Use smaller scale ];  var create_annotated_collection = function(image_and_id) { var img = image_and_id[0]; var image_id = image_and_id[1]; print(image_id); var img_out = img.visualize(visualization) //.clip(geometry)//.paint(municipalities, 'FF0000', 2) .set({'label': image_id}); Map.addLayer(img_out); var annotated = text.annotateImage(img_out, {}, Bayern, annotations); annotated_collection.add(annotated); return 0; };  var municipalities_geom = geometry;  var n = composite_name_list_l7.size().getInfo(); print(n); for (var i = 0; i &lt; n; i++) { var img_info = ee.List(composite_name_list_l7.get(i)); print(img_info); var img = ee.Image(img_info.get(0)); var img_id = ee.String(img_info.get(1)); var year = ee.String(ee.List(img_id.split(\"TO\").get(1))); var year = ee.String(year.split(\"-\").get(0)); var month = ee.String(ee.List(img_id.split(\"-\").get(0))); var img_id_ = year.getInfo() // + \"_\" + month.getInfo(); var img_out = img.visualize(visualization) //.paint(geometry, 'FF0000', 2) .set({'label': img_id_}); var annotated = text.annotateImage(img_out, {}, buffered_extent, annotations); //Map.addLayer(annotated); var annotated_collection_list = annotated_collection_list.add(annotated) }  var annotated_col = ee.ImageCollection(annotated_collection_list)  // Define GIF visualization parameters. var gifParams = { 'region': buffered_extent, 'dimensions': 500,  //'crs': 'EPSG:32632', 'framesPerSecond': .4 };  // Print the GIF URL to the console. print(annotated_col.getVideoThumbURL(gifParams)); // Render the GIF animation in the console. print(ui.Thumbnail(annotated_col, gifParams)); ```  <p>Google Earth Engine App</p> <p> <sup><sub>Please Note: All examples provided in this documentation have been created within the Google Earth Engine platform with the intention of ensuring reproducibility. If you encounter any issues or have questions, feel free to reach out to me at rogeralmengor@gmail.com. The code is made available for public use without any legal restrictions, but I would greatly appreciate it if you could acknowledge my efforts in developing these tools. Your recognition would mean a lot to me as a fellow developer.</sub></sup></p>"},{"location":"portfolio/Languages/Python/","title":"Python","text":""},{"location":"portfolio/Languages/Python/#download-imagery-using-the-asyncio-library","title":"\ud83d\udcbe Download imagery using the Asyncio library","text":"<p>Python has become the go-to programming language for data analysts and AI professionals in recent years. While it's praised for its simplicity and extensive libraries, developers often criticize its speed. However, by optimizing code and leveraging Python's built-in concurrency features, we can significantly improve performance, especially for I/O-bound tasks. In this practical tutorial, we'll explore two approaches to downloading satellite imagery using the Google Earth Engine API: a sequential method and an asynchronous method using asyncio. Asyncio, introduced in Python 3.4 (2014), is particularly well-suited for I/O-bound tasks like API calls and file downloads. We'll demonstrate these concepts by downloading Sentinel-2 satellite images for a region in David, Chiriqu\u00ed, Panama. Our experiment will compare the performance of both methods, providing insights into the benefits of asynchronous programming for data retrieval tasks. This tutorial focuses on practical implementation rather than deep theoretical concepts. By the end, you'll have a better understanding of how to optimize Python code for I/O-bound scenarios, enhancing your geospatial data processing toolkit. Let's start with the code explanation:</p>"},{"location":"portfolio/Languages/Python/#1-setting-up-the-environment","title":"1. Setting Up the Environment:","text":"<p>First, we need to import the necessary libraries and initialize our environment:</p> Code <pre><code>import os\nimport pathlib\nimport time\nimport asyncio\nfrom functools import partial\n\nimport ee\nimport geemap\nimport nest_asyncio\n\n# Apply nest_asyncio to allow running asyncio within Jupyter or similar environments\nnest_asyncio.apply()\n\n# Initialize Earth Engine\ntry:\n    ee.Initialize()\nexcept Exception:\n    ee.Authenticate()\n    ee.Initialize(project=\"ee-thebeautyofthepixel\")\n\n# Define constants\nOUT_DIR = os.path.expanduser(\"~/Downloads\")\nSTART_DATE = \"2024-01-01\"\nEND_DATE = \"2024-07-31\"\nCOLLECTION_ID = \"COPERNICUS/S2_SR\"\nCENTER_LAT, CENTER_LON = 8.3958, -82.4350\nSIDE_LENGTH = 0.09  # roughly 10 km in degrees\n\n# Create output directory\npathlib.Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n\n# Define the bounding box\nbbox = ee.Geometry.Rectangle([\n    CENTER_LON - SIDE_LENGTH/2,  # min longitude\n    CENTER_LAT - SIDE_LENGTH/2,  # min latitude\n    CENTER_LON + SIDE_LENGTH/2,  # max longitude\n    CENTER_LAT + SIDE_LENGTH/2   # max latitude\n])\n</code></pre> <p>In this section, we set up our working environment by importing required libraries and initializing the Earth Engine API. We also define our constants, including the geographical area of interest centered on David, Chiriqu\u00ed, Panama.</p>"},{"location":"portfolio/Languages/Python/#2-filter-image-collection","title":"2. Filter image collection:","text":"<p>Next, we filter the Sentinel-2 image collection to get the images we need:</p> Code <pre><code># Filter image collection\ncollection = ee.ImageCollection(COLLECTION_ID) \\\n    .filterDate(START_DATE, END_DATE) \\\n    .filterBounds(bbox) \\\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 85))\n\nl2a_images = collection.map(lambda i: i.unmask(-1))\nbandNames_l2a = l2a_images.aggregate_array('system:index')\nimage_ids = [image_id for image_id in bandNames_l2a.getInfo()]\n</code></pre> <p>This step narrows down our dataset to the specific images we want to download, based on date range, location, and cloud cover.</p>"},{"location":"portfolio/Languages/Python/#3-define-download-functions","title":"3. Define download functions:","text":"<p>To compare sequential and asynchronous downloads, we define several functions:</p> Code <pre><code>def download_snippet(image_id:str, collection_id:str, roi:ee.Geometry, fc, output_folder)-&gt;str:\n    \"\"\"Downloads the 4 images but only for 1 image id\"\"\"\n    print(f\"Downloading {image_id}\")\n    L2A_image = ee.Image(f\"{collection_id}/{image_id}\").clip(roi)\n    vis_params = {\n            'bands': ['B8', 'B4', 'B3'],\n            'min': 0,\n            'max': 5000,\n            'gamma': [1.35, 1.35, 1.35]\n        }\n    L2A_image_to_export = L2A_image.visualize(**vis_params) \\\n            .clip(roi) \\\n            .paint(fc, '0000ffff', 2)\n    _out = output_folder + \"/\" + image_id + \"_L2A.tif\"\n    geemap.download_ee_image(L2A_image_to_export, _out, scale=2)\n    return L2A_image_to_export\n\nasync def download_snippet_async(image_id: str, collection_id: str, roi: ee.Geometry, fc, output_folder) -&gt; str:\n    \"\"\"Downloads the image for 1 image id asynchronously\"\"\"\n    print(f\"Downloading {image_id}\")\n\n    # Create a partial function for the synchronous parts\n    sync_func = partial(download_snippet_sync, image_id, collection_id, roi, fc, output_folder)\n\n    # Run the synchronous function in a thread pool\n    loop = asyncio.get_event_loop()\n    result = await loop.run_in_executor(None, sync_func)\n\n    return f\"Downloaded {image_id}\"\n\ndef download_snippet_sync(image_id: str, collection_id: str, roi: ee.Geometry, fc, output_folder) -&gt; str:\n    \"\"\"Synchronous part of the download function\"\"\"\n    L2A_image = ee.Image(f\"{collection_id}/{image_id}\").clip(roi)\n    vis_params = {\n        'bands': ['B8', 'B4', 'B3'],\n        'min': 0,\n        'max': 5000,\n        'gamma': [1.35, 1.35, 1.35]\n    }\n    L2A_image_to_export = L2A_image.visualize(**vis_params) \\\n        .clip(roi) \\\n        .paint(fc, '0000ffff', 2)\n    _out = f\"{output_folder}/{image_id}_L2A.tif\"\n    geemap.download_ee_image(L2A_image_to_export, _out, scale=2)\n    return L2A_image_to_export\n\nasync def download_all_snippets_async(image_ids, collection_id, roi, fc, output_folder):\n    tasks = []\n    for image_id in image_ids:\n        task = asyncio.create_task(download_snippet_async(\n            image_id, collection_id, roi, fc, output_folder\n        ))\n        tasks.append(task)\n    return await asyncio.gather(*tasks)\n</code></pre> <p>These functions handle the actual download process for both sequential and asynchronous methods. The asynchronous functions use Python's asyncio library to enable concurrent downloads.</p>"},{"location":"portfolio/Languages/Python/#4-running-comparison","title":"4. Running comparison","text":"<p>Finally, we perform both sequential and asynchronous downloads and compare their performance:</p> Code <pre><code># Sequential download\nstart_time_sequential = time.perf_counter()\n\nfor image_id in image_ids:\n    download_snippet(image_id=image_id, collection_id=COLLECTION_ID,\n                     roi=bbox, fc=bbox, output_folder=OUT_DIR)\n\nend_time_sequential = time.perf_counter()\nexecution_time_sequential = end_time_sequential - start_time_sequential\nprint(f\"Total time taken for sequential download: {execution_time_sequential:.4f} seconds\")\n\n# Asynchronous download\nstart_time_async = time.perf_counter()\n\nloop = asyncio.get_event_loop()\nresults = loop.run_until_complete(download_all_snippets_async(image_ids, COLLECTION_ID, bbox, bbox, OUT_DIR))\n\nend_time_async = time.perf_counter()\nexecution_time_async = end_time_async - start_time_async\nprint(f\"Total time taken for asynchronous download: {execution_time_async:.4f} seconds\")\n\n# Print results\nfor result in results:\n    print(result)\n\n# Compare performance\nspeedup = execution_time_sequential / execution_time_async\nprint(f\"Speedup factor: {speedup:.2f}x\")\n</code></pre> <p>This section demonstrates how to execute both download methods and measure their performance. By comparing the execution times, we can see the benefits of asynchronous programming for I/O-bound tasks like downloading satellite imagery.</p>"},{"location":"portfolio/Languages/Python/#conclusion","title":"Conclusion:","text":"<p>Proper implementation of asynchronous programming can lead to substantial performance improvements. For geospatial data processing, optimizing data retrieval can significantly reduce overall processing time. As in some videos I've seen in the past recommend: weigh the use of asyncronous Programming for response-driven applications, which depends on external services. If your process is depending on your CPU power, then go for multiprocessing as an option, and to try to utilize the full capacity of your multicore machine. Only by understanding and applying these concepts (experimenting I would suggest), data analysts and AI professionals can significantly improve the performance of their geospatial data processing workflows.</p> <p>For the record, I will post in the next lines, the complete code, so you can play around with it, and modify it according to your needs.</p> Code ```python title=\"download_s2_snippets.py\" linenums=\"1\" import os import pathlib import time import asyncio from functools import partial  import ee import geemap import nest_asyncio  # Apply nest_asyncio to allow running asyncio within Jupyter or similar environments nest_asyncio.apply()  # Initialize Earth Engine try:     ee.Initialize() except Exception:     ee.Authenticate()     ee.Initialize(project=\"ee-thebeautyofthepixel\")  # Define constants OUT_DIR = os.path.expanduser(\"~/Downloads\") START_DATE = \"2024-01-01\" END_DATE = \"2024-07-31\" COLLECTION_ID = \"COPERNICUS/S2_SR\" CENTER_LAT, CENTER_LON = 8.3958, -82.4350 SIDE_LENGTH = 0.09  # roughly 10 km in degrees  # Create output directory pathlib.Path(OUT_DIR).mkdir(parents=True, exist_ok=True)  # Define the bounding box bbox = ee.Geometry.Rectangle([     CENTER_LON - SIDE_LENGTH/2,  # min longitude     CENTER_LAT - SIDE_LENGTH/2,  # min latitude     CENTER_LON + SIDE_LENGTH/2,  # max longitude     CENTER_LAT + SIDE_LENGTH/2   # max latitude ])  # Filter image collection collection = ee.ImageCollection(COLLECTION_ID) \\     .filterDate(START_DATE, END_DATE) \\     .filterBounds(bbox) \\     .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 85))  l2a_images = collection.map(lambda i: i.unmask(-1)) bandNames_l2a = l2a_images.aggregate_array('system:index') image_ids = [image_id for image_id in bandNames_l2a.getInfo()]  # Define download functions  def download_snippet(image_id:str, collection_id:str, roi:ee.Geometry, fc, output_folder)-&gt;str:     \"\"\"Downloads the 4 images but only for 1 image id\"\"\"     print(f\"Downloading {image_id}\")     L2A_image = ee.Image(f\"{collection_id}/{image_id}\").clip(roi)     vis_params = {             'bands': ['B8', 'B4', 'B3'],             'min': 0,             'max': 5000,             'gamma': [1.35, 1.35, 1.35]         }     L2A_image_to_export = L2A_image.visualize(**vis_params) \\             .clip(roi) \\             .paint(fc, '0000ffff', 2)     _out = output_folder + \"/\" + image_id + \"_L2A.tif\"     geemap.download_ee_image(L2A_image_to_export, _out, scale=2)     return L2A_image_to_export  async def download_snippet_async(image_id: str, collection_id: str, roi: ee.Geometry, fc, output_folder) -&gt; str:     \"\"\"Downloads the image for 1 image id asynchronously\"\"\"     print(f\"Downloading {image_id}\")      # Create a partial function for the synchronous parts     sync_func = partial(download_snippet_sync, image_id, collection_id, roi, fc, output_folder)      # Run the synchronous function in a thread pool     loop = asyncio.get_event_loop()     result = await loop.run_in_executor(None, sync_func)      return f\"Downloaded {image_id}\"  def download_snippet_sync(image_id: str, collection_id: str, roi: ee.Geometry, fc, output_folder) -&gt; str:     \"\"\"Synchronous part of the download function\"\"\"     L2A_image = ee.Image(f\"{collection_id}/{image_id}\").clip(roi)     vis_params = {         'bands': ['B8', 'B4', 'B3'],         'min': 0,         'max': 5000,         'gamma': [1.35, 1.35, 1.35]     }     L2A_image_to_export = L2A_image.visualize(**vis_params) \\         .clip(roi) \\         .paint(fc, '0000ffff', 2)     _out = f\"{output_folder}/{image_id}_L2A.tif\"     geemap.download_ee_image(L2A_image_to_export, _out, scale=2)     return L2A_image_to_export  async def download_all_snippets_async(image_ids, collection_id, roi, fc, output_folder):     tasks = []     for image_id in image_ids:         task = asyncio.create_task(download_snippet_async(             image_id, collection_id, roi, fc, output_folder         ))         tasks.append(task)     return await asyncio.gather(*tasks)  # Sequential download start_time_sequential = time.perf_counter()  for image_id in image_ids:     download_snippet(image_id=image_id, collection_id=COLLECTION_ID,                      roi=bbox, fc=bbox, output_folder=OUT_DIR)  end_time_sequential = time.perf_counter() execution_time_sequential = end_time_sequential - start_time_sequential print(f\"Total time taken for sequential download: {execution_time_sequential:.4f} seconds\")  # Asynchronous download start_time_async = time.perf_counter()  loop = asyncio.get_event_loop() results = loop.run_until_complete(download_all_snippets_async(image_ids, COLLECTION_ID, bbox, bbox, OUT_DIR))  end_time_async = time.perf_counter() execution_time_async = end_time_async - start_time_async print(f\"Total time taken for asynchronous download: {execution_time_async:.4f} seconds\")  # Print results for result in results:     print(result)  # Compare performance speedup = execution_time_sequential / execution_time_async print(f\"Speedup factor: {speedup:.2f}x\") ```"}]}